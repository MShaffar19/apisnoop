* Running APISnoop

** Start a Branch on this repo

This will allow for a new site to be deployed specifically for your data.

** Specifying Audit Logs

The audit logs to process are outlined in our [[./audit-sources.yaml][audit-sources.yaml]], located in the root of this repo.  Each field in this yaml is required, and explained below.

#+BEGIN_SRC yaml
# where the raw audit logs are located.
source: prow.k8s.io
# which buckets you would like processed
buckets:
  ci-kubernetes-e2e-gce-cos-k8sstable3-default:
# you can specify multiple jobs per bucket
# job should be explicitly set as strings.
    jobs:
      - '1121083339638312961'
  ci-kubernetes-e2e-gce-cos-k8sstable2-default:
    jobs:
      - '1121457989778149377'
  ci-kubernetes-e2e-gce-cos-k8sstable1-default:
    jobs:
      - '1121581392354873344'
  ci-kubernetes-e2e-gce-cos-k8sbeta-default:
    jobs:
      - '1121564030004105216'
  ci-kubernetes-e2e-gci-gce:
    jobs:
      - '1121334929389522946'
# which bucket and job shows on first page load of the site.
default-view:
  bucket: ci-kubernetes-e2e-gci-gce
  job: '1121334929389522946'
#+END_SRC

** Open a Pull Request in this repo

This will trigger a number of jobs to occur, which you can track in the pull request.  The main things happening are:
- We check ~audit-sources.yaml~ and use this to generate data.
- We store this processed data on Google Storage, in a specific ~gs:/apisnoop bucket~.
- A site is built from the code in ~app~ and deployed to netlify.
- As part of the deployment we run ~./update.sh~ to copy ~audit-sources.yaml~ to the app's public folder, and query ~gs://apisnoop~ to get the path to the processed logs.
- a deploy preview is generated by netlify, with a link provided in the details of our prow job.

** Viewing your Site

You can grab the link for the netlify preview in the Checks panel of the pull request, by clicking the details link next to ~netlify/apisnoop/deploy-preview~

* Contributing

** Contribution to Data Processing

As we make a fresh deployment per branchk, you can not only adjust the audit logs we look at, but the ways in which these audit logs are processed.

The core of the data processing is written in Python, and held in our [[file:data-gen/][./data-gen]] folder.

** Contributions to the App

Our front-end site is written with React and Redux, and held in our [[file:app/][./app]] folder.  There is a README located within that folder with more details on the structure and patterns of the site.
