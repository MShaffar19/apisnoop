#+TITLE: Meta.org Archive
#    -*- mode: org -*-
Archived entries from file /zfs/home/zz/ii/apisnoop_v3/org/meta.org
* Purpose
To hold old code and headings from meta.org that may still be useful for exploration.
* Original Audit Events Table
** columns
*** audit_id

#+NAME: audit_id
#+BEGIN_SRC sql-mode
    audit_id uuid NOT NULL,
#+END_SRC

This is a UUID!
But there are multiple occurences in a single log file.

**** Examples
#+BEGIN_SRC json
  auditID: "c0793350-e7fe-42ce-93e6-8436a0eb3b39",
#+END_SRC
**** 285593 times each one occurs once
#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq .auditID | sort | uniq -c | grep -v '2 "' | wc -l
#+END_SRC
**** 8141 times a single uuid shows up twice
#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq .auditID | sort | uniq -c | grep -v '1 "' | wc -l
#+END_SRC
**** When a UUID shows up twice, the only diff is stage and stageTimestamp
#+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq -c '. | select( .auditID | contains("ffe9adb2-6917-49ed-b823-72c4fe4355e0"))' | jq 
#+END_SRC

  "stage": "ResponseStarted => ResponseComplete"
  "stageTimestamp": "2019-06-17T05:19:17.898138Z",

#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq .auditID | sort | uniq -c | grep -v '1 "' | wc -l
#+END_SRC

*** testrun_id
We need something to differentiate test run
#+NAME: testrun_id
#+BEGIN_SRC sql-mode
    testrun_id text,
#+END_SRC
*** op_id
#+NAME: op_id
#+BEGIN_SRC sql-mode
    op_id text,
#+END_SRC
*** stage
    "stage"
#+NAME: stage
#+BEGIN_SRC sql-mode
  stage text NOT NULL,
#+END_SRC
*** level
#+NAME: level
#+BEGIN_SRC sql-mode
  level text NOT NULL,
#+END_SRC

level: "Request", "Metadata", "RequestResponse"

I'm not sure here, but I feel like we should only be looking at RequestResponse... not all three.
Huh, that was wrong.. the counts differ wildly:

**** 171724 Requests
#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq -c '. | select( .level | contains("Request"))' | jq -r .auditID | sort | uniq | wc -l
#+END_SRC
**** 122010 Metadata
#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq -c '. | select( .level | contains("RequestResponse"))' | jq -r .auditID | sort | uniq | wc -l
#+END_SRC

**** 26016 RequestResponse
#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq -c '. | select( .level | contains("RequestResponse"))' | jq -r .auditID | sort | uniq | wc -l
#+END_SRC

*** verb
#+NAME: verb
#+BEGIN_SRC sql-mode
  verb text NOT NULL,
#+END_SRC
An http verb != endpoint verb:
stage has quite a few values
- create
- delete
- deletecollection,
- get
- list
- patch
- update
- watch
*** request_uri
#+NAME: request_uri
#+BEGIN_SRC sql-mode
  request_uri text NOT NULL,
#+END_SRC

We'll need to use this to match against the OpenAPISpec to find the endpoint.

request_uri: "/api/v1/namespaces/kube-system/pods/etcd-empty-dir-cleanup-bootstrap-e2e-master",
*** user_agent
#+NAME: user_agent
#+BEGIN_SRC sql-mode
  user_agent text,
#+END_SRC
For e2e.test we added support to append -- and the test name at that point it time:

userAgent: "kubelet/v1.16.0 (linux/amd64) kubernetes/0e499be",

It may make sense to split on '--' an store what follows as the testName.
*** test_name
#+NAME: test_name
#+BEGIN_SRC sql-mode
  test_name text,
#+END_SRC

This isn't a direct mapping, we create it if the userAgent contains '--' followed by the test name.
For now we only see this with e2e.test.
*** request_ts
    "requestReceivedTimestamp"
#+NAME: request_ts
#+BEGIN_SRC sql-mode
  request_ts timestamp with time zone,
#+END_SRC
*** stage_ts

Noting that when we have a responseComplete, it's always paid with a responseStarted.
The UUID and everything else is the same, other than the timestamp.
I suspect this is only generated for requests that take a while.

stage: "ResponseComplete", "ResponseStarted"
#+NAME: stage_ts
#+BEGIN_SRC sql-mode
  stage_ts timestamp with time zone,
#+END_SRC
*** Kind / apiVersion                                                :unused:

For every singe one the values are the same:
kind: "Event"
apiVersion: "audit.k8s.io/v1"

#+NAME: kind
#+BEGIN_SRC sql-mode
  kind text,
  "apiVersion" text,
#+END_SRC
*** annotations                                                      :unused:

This is a json blog... not sure how to handle yet
https://blog.hasura.io/postgres-json-and-jsonb-type-support-on-graphql-41f586e47536/

Unsure we need annotations for now as they may be good for understanding a
specific test, the data doesn't aggregate well.

#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq -r .annotations | sort | uniq
#+END_SRC

A good number of them seem to be allow or deny + reason:

#+BEGIN_SRC json
  "annotations": {
    "authorization.k8s.io/decision": "allow",
    "authorization.k8s.io/reason": ""
  }
#+END_SRC

#+BEGIN_SRC sql-mode
  annotations jsonb,
#+END_SRC
*** sourceIPs                                                        :unused:
#+BEGIN_SRC sql-mode
  "sourceIP" text,
#+END_SRC

Could likely identify pods in this way, but not useful at this time.
sourceIPs: ["1.1.1.1"],
*** Unused Fields                                                    :unused:
The id could probably be dropped in favor of UUID, if we only capture ResponseStarted.
#+BEGIN_SRC sql-mode
  -- I'm unsure what this is
  -- This is to point back to the job that created these logs
  job_log_id integer NOT NULL
  -- should it be an iteger?
  -- maybe get rid of it completely?
  id integer NOT NULL,
#+END_SRC

** table

#+BEGIN_SRC tmate
  cd ~/ii/apisnoop_v3
  python3 import_entries.py
#+END_SRC

*** SQL VIEW for JSON BLOBS
This has one column... event which is a jsonb.

#+NAME: CREATE TABLE audit_events
#+BEGIN_SRC sql-mode :noweb yes :notangle ../apps/hasura/migrations/230_table_audit_events.up.sql
  CREATE TABLE public.audit_events (
    <<audit_id>>
    <<testrun_id>>
    <<op_id>>
    <<stage>>
    <<level>>
    <<verb>>
    <<request_uri>>
    <<user_agent>>
    <<test_name>>
    <<requestObject.kind>>
    <<requestObject.apiVersion>>
    <<requestObject.metadata>>
    <<requestObject.spec>>
    <<requestObject.status>>
    <<responseObject.kind>>
    <<responseObject.apiVersion>>
    <<responseObject.metadata>>
    <<responseObject.spec>>
    <<responseObject.status>>
    <<request_ts>>
    <<stage_ts>>
    CONSTRAINT audit_id_stage PRIMARY KEY (audit_id, stage)
  );
  -- Indexes
  create index audit_events_op_id on audit_events(op_id);
  create index audit_events_testrun_id on audit_events(testrun_id);
  --  create index audit_events_stage on audit_events(stage);
  create index audit_events_user_agent on audit_events(user_agent);
  create index audit_events_test_name on audit_events(test_name);
  create index audit_events_verb on audit_events(verb);
  create index audit_events_request_uri on audit_events(request_uri);
#+END_SRC

#+RESULTS: CREATE TABLE audit_events
#+begin_src sql-mode
CREATE TABLE
CREATE INDEX
CREATE INDEX
CREATE INDEX
#+end_src

#+NAME: track_table audit_events
#+BEGIN_SRC sql-mode :noweb yes :notangle ../apps/hasura/migrations/230_track_audit_events.up.yaml
- type: track_table
  args:
    schema: public
    name: audit_events
#+END_SRC

After creating the table, we have to go to the console:
hasura.$USER.sharing.io
http://localhost:8080/console/data/schema/public
And click on [Track All] or [Track] for the table.

I also tracked the following in network traffic, but have yet to execute them
via a directy grahpql query.

#+BEGIN_SRC shell :directory ~/apisnoop_v3
hasura init --endpoint http://localhost:8080/v1/graphql
export HASURA_GRAPHQL_ADMIN_SECRET=X
# --admin-secret "X"
#+END_SRC

#+BEGIN_SRC sql-mode
  CREATE OR REPLACE VIEW "public"."events" AS 
   SELECT audit_events.auditID AS uuid,
      audit_events.level AS level,
      audit_events.verb AS verb,
      audit_events.requestURI AS uri,
      audit_events.userAgent AS useragent,
      audit_events.testName AS testName,
      -- ((audit_events.event -> 'requestObject'::text) ->> 'apiVersion'::text) AS apiversion,
      ((audit_events.event -> 'requestObject'::text) ->> 'kind'::text) AS kind,
      ((audit_events.event -> 'requestObject'::text) ->> 'metadata'::text) AS metadata,
      ((audit_events.event -> 'requestObject'::text) ->> 'spec'::text) AS spec,
      ((audit_events.event -> 'requestObject'::text) ->> 'status'::text) AS requeststatus,
      ((audit_events.event -> 'responseObject'::text) ->> 'status'::text) AS status,
      ((audit_events.event -> 'responseObject'::text) ->> 'kind'::text) AS responsekind,
      ((audit_events.event -> 'responseObject'::text) ->> 'metadata'::text) AS responsemetadata,
      ((audit_events.event -> 'responseObject'::text) ->> 'spec'::text) AS responsespec
     FROM audit_events;
#+END_SRC

#+RESULTS:
#+begin_src sql-mode
ERROR:  column audit_events.event does not exist
LINE 2:  SELECT (audit_events.event -> 'auditID'::text) AS uuid,
                 ^
#+end_src

** sequence

#+BEGIN_SRC sql-mode
CREATE SEQUENCE public.audit_events_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.audit_events_id_seq OWNED BY public.audit_events.id;
#+END_SRC

#+RESULTS:
: CREATE SEQUENCE
: ALTER SEQUENCE
** constraints

#+RESULTS:
: ALTER TABLE
: ALTER TABLE

#+BEGIN_SRC sql-mode
ALTER TABLE ONLY public.audit_events
    ADD CONSTRAINT "audit_events_auditID_key" UNIQUE ("auditID");
ALTER TABLE ONLY public.audit_events
    ADD CONSTRAINT audit_events_pkey PRIMARY KEY (id);
#+END_SRC
* Original api_resources_fields view
#+NAME: Older Properties View
#+BEGIN_SRC sql-mode :eval never-export :notangle ../apps/hasura/migrations/200_view_api_resources_fields.up.sql
  -- DROP VIEW api_resources_properties;
  -- DROP MATERIALIZED VIEW api_resources_properties;
  CREATE VIEW "public"."api_resources_fields" AS 
    SELECT api_resources.id AS type_id,
           d.key AS property,
           CASE
           WHEN ((d.value ->> 'type'::text) IS NULL) THEN 'subtype'::text
           ELSE (d.value ->> 'type'::text)
             END AS param_type,
           replace(
             CASE
             WHEN ((d.value ->> 'type'::text) = 'string'::text) THEN 'string'::text
             WHEN ((d.value ->> 'type'::text) IS NULL) THEN (d.value ->> '$ref'::text)
             WHEN ((d.value ->> 'type'::text) = 'array'::text)
              AND ((d.value -> 'items'::text) ->> 'type'::text) IS NULL
               THEN ((d.value -> 'items'::text) ->> '$ref'::text)
             WHEN ((d.value ->> 'type'::text) = 'array'::text)
              AND ((d.value -> 'items'::text) ->> '$ref'::text) IS NULL
               THEN ((d.value -> 'items'::text) ->> 'type'::text)
             ELSE 'integer'::text
             END, '#/definitions/','') AS param_kind,
           (d.value ->> 'description'::text) AS description,
           (d.value ->> 'format'::text) AS format,
           (d.value ->> 'x-kubernetes-patch-merge-key'::text) AS merge_key,
           (d.value ->> 'x-kubernetes-patch-strategy'::text) AS patch_strategy,
           -- CASE
           --   WHEN d.key is null THEN false
           --   WHEN (api_resources.required_params ? d.key) THEN true
           --   ELSE false
           --     END
           --   AS required,
           -- with param type also containing array, we don't need array as a boolean
           -- CASE
           -- WHEN ((d.value ->> 'type'::text) = 'array'::text) THEN true
           -- ELSE false
           --  END AS "array"
           d.value
      FROM (api_resources
            JOIN LATERAL jsonb_each(api_resources.properties) d(key, value) ON (true))
     ORDER BY api_resources.id;
#+END_SRC
* #40: PodSpec and Audit Events
  :PROPERTIES:
  :ARCHIVE_TIME: 2019-08-14 Wed 23:52
  :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
  :ARCHIVE_CATEGORY: meta
  :END:
  There is only a single resource, it seems, that references podspec.  So our list of 'podspec fields' is really coming from this resource.
  
  #+RESULTS: Properties of podspec
  #+begin_src sql-mode
               field             |            name            
  -------------------------------+----------------------------
   hostIPC                       | io.k8s.api.core.v1.PodSpec
   hostPID                       | io.k8s.api.core.v1.PodSpec
   volumes                       | io.k8s.api.core.v1.PodSpec
   affinity                      | io.k8s.api.core.v1.PodSpec
   hostname                      | io.k8s.api.core.v1.PodSpec
   nodeName                      | io.k8s.api.core.v1.PodSpec
   overhead                      | io.k8s.api.core.v1.PodSpec
   priority                      | io.k8s.api.core.v1.PodSpec
   dnsConfig                     | io.k8s.api.core.v1.PodSpec
   dnsPolicy                     | io.k8s.api.core.v1.PodSpec
   subdomain                     | io.k8s.api.core.v1.PodSpec
   containers                    | io.k8s.api.core.v1.PodSpec
   hostAliases                   | io.k8s.api.core.v1.PodSpec
   hostNetwork                   | io.k8s.api.core.v1.PodSpec
   tolerations                   | io.k8s.api.core.v1.PodSpec
   nodeSelector                  | io.k8s.api.core.v1.PodSpec
   restartPolicy                 | io.k8s.api.core.v1.PodSpec
   schedulerName                 | io.k8s.api.core.v1.PodSpec
   initContainers                | io.k8s.api.core.v1.PodSpec
   readinessGates                | io.k8s.api.core.v1.PodSpec
   serviceAccount                | io.k8s.api.core.v1.PodSpec
   securityContext               | io.k8s.api.core.v1.PodSpec
   imagePullSecrets              | io.k8s.api.core.v1.PodSpec
   preemptionPolicy              | io.k8s.api.core.v1.PodSpec
   runtimeClassName              | io.k8s.api.core.v1.PodSpec
   priorityClassName             | io.k8s.api.core.v1.PodSpec
   enableServiceLinks            | io.k8s.api.core.v1.PodSpec
   serviceAccountName            | io.k8s.api.core.v1.PodSpec
   ephemeralContainers           | io.k8s.api.core.v1.PodSpec
   activeDeadlineSeconds         | io.k8s.api.core.v1.PodSpec
   shareProcessNamespace         | io.k8s.api.core.v1.PodSpec
   topologySpreadConstraints     | io.k8s.api.core.v1.PodSpec
   automountServiceAccountToken  | io.k8s.api.core.v1.PodSpec
   terminationGracePeriodSeconds | io.k8s.api.core.v1.PodSpec
  (34 rows)

  #+end_src

  #+RESULTS:
  #+begin_src sql-mode
              name            
  ----------------------------
   io.k8s.api.core.v1.PodSpec
  (1 row)
  #+end_src
  
  One thing we can try is to quickly connect the audit event to its api_operation, so that we get a standard definition of what happened.
  
  From there, we could see if that operation is part of the podSpec in some way.
 
  #+NAME: Properties of podspec
  #+BEGIN_SRC sql-mode
    SELECT 
      resource_field as field,
      api_resource_name as name
      FROM
          api_resources_fields
      WHERE api_resources_fields.api_resource_name ILIKE '%podspec%';
  #+END_SRC

  #+NAME: adding RegEx matching
  #+BEGIN_SRC sql-mode
    SELECT
      events.request_uri,
      ops.operation_id
      FROM audit_events events
         JOIN api_operations ops ON events.request_uri ~ ops.regex
      LIMIT 3;
  #+END_SRC

  #+RESULTS: adding RegEx matching
  #+begin_src sql-mode
                                      request_uri                                    |                         operation_id                          
  -----------------------------------------------------------------------------------+---------------------------------------------------------------
   /apis/rbac.authorization.k8s.io/v1beta1/namespaces/provisioning-6870/rolebindings | deleteRbacAuthorizationV1beta1CollectionNamespacedRoleBinding
   /apis/rbac.authorization.k8s.io/v1beta1/namespaces/provisioning-6870/rolebindings | listRbacAuthorizationV1beta1NamespacedRoleBinding
   /apis/rbac.authorization.k8s.io/v1beta1/namespaces/provisioning-6870/rolebindings | createRbacAuthorizationV1beta1NamespacedRoleBinding
  (3 rows)

  #+end_src

* From metasave.org
** Working with this repo/org file
*** Work happens in Org first
    Within ii, our emphasis is on the documentation/org-file first.  
    We can document and craft the queries for our db, then tangle them into our migration files.
    as such: 
    *NOTE: Don't commit the hasura/migrations, they should be tangled from the org file.*
    In the future, we may add a commit hook that tangles org => hasura
** TODO Starting up your database
*** listing tables
 #+BEGIN_SRC sql-mode
 \conninfo
 \d+
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
 You are connected to database "zz" as user "zz" on host "172.17.0.1" at port "5432".
 SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)
                                  List of relations
  Schema |            Name            |   Type   | Owner |    Size    | Description 
 --------+----------------------------+----------+-------+------------+-------------
  public | api_operations             | view     | zz    | 0 bytes    | 
  public | api_operations_parameters  | view     | zz    | 0 bytes    | 
  public | api_operations_responses   | view     | zz    | 0 bytes    | 
  public | api_resources              | view     | zz    | 0 bytes    | 
  public | api_resources_fields       | view     | zz    | 0 bytes    | 
  public | operations_with_parameters | view     | zz    | 0 bytes    | 
  public | over                       | view     | zz    | 0 bytes    | 
  public | raw_paths                  | view     | zz    | 0 bytes    | 
  public | raw_swaggers               | table    | zz    | 10080 kB   | 
  public | raw_swaggers_id_seq        | sequence | zz    | 8192 bytes | 
 (10 rows)

 #+end_src

*** dropping all data
 #+NAME: do not run
 #+BEGIN_SRC sql-mode :eval ask
   drop table api_operations cascade;
   drop table audit_events cascade;
   drop table raw_swaggers cascade;
   drop schema hdb_catalog cascade;
   drop schema hdb_views cascade;
 #+END_SRC

 #+RESULTS: do not run
 #+begin_src sql-mode
 ERROR:  table "api_operations" does not exist
 #+end_src

*** setting up the hasura postgresql-permissions

 Run the following as the postgres user via psql:
 https://docs.hasura.io/1.0/graphql/manual/deployment/postgres-permissions.html

 #+NAME: emacs-user
 #+BEGIN_SRC shell :results silent
 echo -n $USER
 #+END_SRC

 #+NAME: create database and granting all privs to a user
 #+BEGIN_SRC sql-mode :noweb yes :tangle ../hasura/db_setup.sql

 create database <<emacs-user()>>;
 -- create user myuser with encrypted password 'mypass';
 grant all privileges on database <<emacs-user()>> to <<emacs-user()>>;
 create role dba with superuser noinherit;
 grant dba to <<emacs-user()>>;
 \connect <<emacs-user()>>
 -- we write python functions
 CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
 CREATE EXTENSION IF NOT EXISTS plpython3u;
 CREATE EXTENSION IF NOT EXISTS pgcrypto;
 CREATE SCHEMA IF NOT EXISTS hdb_catalog;
 CREATE SCHEMA IF NOT EXISTS hdb_views;
 -- make the user an owner of system schemas
 ALTER SCHEMA hdb_catalog OWNER TO <<emacs-user()>>;
 ALTER SCHEMA hdb_views OWNER TO <<emacs-user()>>;
 GRANT SELECT ON ALL TABLES IN SCHEMA information_schema TO <<emacs-user()>>;
 GRANT SELECT ON ALL TABLES IN SCHEMA pg_catalog TO <<emacs-user()>>;
 GRANT USAGE ON SCHEMA public TO <<emacs-user()>>;
 GRANT ALL ON ALL TABLES IN SCHEMA public TO <<emacs-user()>>;
 GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO <<emacs-user()>>;
 GRANT pg_execute_server_program TO <<emacs-user()>>;
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
 ERROR:  must have admin option on role "pg_execute_server_program"
 #+end_src

 #+NAME: as posgres admin, setup hasura user and db
 #+BEGIN_SRC tmate
 sudo su - postgres -c psql < ~/ii/apisnoop_v3/hasura/db_setup.sql
 #+END_SRC

** TADA make sure hasura has public endpoint
 file:hasura.org
*** TODO secure hasura with simple auth
** Create Tables and Load Data
*** swagger.json

 #+NAME: raw_swaggers
 #+BEGIN_SRC sql-mode :tangle ../hasura/migrations/100_table_raw_swaggers.up.sql
 CREATE TABLE raw_swaggers (
     id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
     ingested_at timestamp DEFAULT CURRENT_TIMESTAMP,
     -- version text NOT NULL,
     -- definition_id text NOT NULL,
     data jsonb NOT NULL
 );
 #+END_SRC

 #+RESULTS: raw_swaggers
 #+begin_src sql-mode
 CREATE TABLE
 #+end_src

 #+NAME: track raw_swaggers
 #+BEGIN_SRC yaml :tangle ../hasura/migrations/100_table_raw_swaggers.up.yaml
 - type: track_table
   args:
     schema: public
     name: raw_swaggers
 #+END_SRC

*** load swagger via curl

 #+NAME: load_swagger_via_curl.py
 #+BEGIN_SRC python :eval never
   # should probably sanitize branch_or_tag
   try:
       from string import Template
       sql = Template("copy raw_swaggers (data) FROM PROGRAM '$curl' (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');").substitute(
           curl =  f'curl https://raw.githubusercontent.com/kubernetes/kubernetes/{branch_or_tag}/api/openapi-spec/swagger.json | jq -c .'
       )
       rv = plpy.execute(sql)
       return "it worked"
   except:
       return "something went wrong"
 #+END_SRC

 #+NAME: load_swagger_via_curl.sql
 #+BEGIN_SRC sql-mode :noweb yes :tangle ../hasura/migrations/120_function_load_swagger_via_curl.up.sql
   set role dba;
   CREATE OR REPLACE FUNCTION load_swagger_via_curl(branch_or_tag text)
   RETURNS text AS $$
   <<load_swagger_via_curl.py>>
   $$ LANGUAGE plpython3u ;
   reset role;
 #+END_SRC

 #+BEGIN_SRC sql-mode :noweb yes :tangle ../hasura/migrations/130_populate_swaggers.up.sql
   delete from raw_swaggers;
   select * from load_swagger_via_curl('master');
   -- select * from load_swagger_via_curl('release-1.15');
   -- select * from load_swagger_via_curl('release-1.14');
   -- select * from load_swagger_via_curl('release-1.13');
   -- select * from load_swagger_via_curl('release-1.12');
   -- select * from load_swagger_via_curl('release-1.11');
   -- select * from load_swagger_via_curl('release-1.10');
 #+END_SRC

 #+BEGIN_SRC sql-mode
   select count(*) from raw_swaggers;
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
  count 
 -------
      7
 (1 row)

 #+end_src

 #+BEGIN_SRC sql-mode
 \dt+
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
                       List of relations
  Schema |     Name     | Type  | Owner | Size  | Description 
 --------+--------------+-------+-------+-------+-------------
  public | raw_swaggers | table | zz    | 13 MB | 
 (1 row)

 #+end_src

** Load Operation Views
*** api_operations view
**** raw_paths view

 #+NAME: raw_paths view
 #+BEGIN_SRC sql-mode :eval never-export :tangle ../hasura/migrations/140_view_raw_paths.up.sql
   CREATE OR REPLACE VIEW "public"."raw_paths" AS 
     SELECT raw_swaggers.id AS raw_swagger_id,
            d.key AS path,
            d.value
       FROM (raw_swaggers
             JOIN LATERAL jsonb_each((raw_swaggers.data -> 'paths'::text)) d(key, value) ON (true))
      ORDER BY d.key;
 #+END_SRC
 #+NAME: track raw_paths
 #+BEGIN_SRC yaml :tangle ../hasura/migrations/140_view_raw_paths.up.yaml
 - type: track_table
   args:
     schema: public
     name: raw_paths
 #+END_SRC

**** regex_from_path function
 #+NAME: regex_from_path.py
 #+BEGIN_SRC python :eval never
   import re
   if path is None:
     return None
   K8S_PATH_VARIABLE_PATTERN = re.compile("{(path)}$")
   VARIABLE_PATTERN = re.compile("{([^}]+)}")
   path_regex = K8S_PATH_VARIABLE_PATTERN.sub("(.*)", path).rstrip('/')
   path_regex = VARIABLE_PATTERN.sub("([^/]*)", path_regex).rstrip('/')
   if not path_regex.endswith(")") and not path_regex.endswith("?"): 
       path_regex += "([^/]*)"
   if path_regex.endswith("proxy"): 
       path_regex += "/?$"
   else:
       path_regex += "$"
   return path_regex
 #+END_SRC

 #+NAME: regex_from_path.sql
 #+BEGIN_SRC sql-mode :noweb yes :tangle ../hasura/migrations/145_function_regex_from_path.up.sql
   set role dba;
   CREATE OR REPLACE FUNCTION regex_from_path(path text)
   RETURNS text AS $$
   <<regex_from_path.py>>
   $$ LANGUAGE plpython3u ;
   reset role;
 #+END_SRC

**** api_operations view
 #+NAME: api_operations view
 #+BEGIN_SRC sql-mode :eval never-export :tangle ../hasura/migrations/150_view_api_operations.up.sql
   -- DROP VIEW api_operations CASCADE;
   CREATE OR REPLACE VIEW "public"."api_operations" AS 
     SELECT (d.value ->> 'operationId'::text) AS operation_id,
            uuid_generate_v1() as id,
            raw_paths.raw_swagger_id as raw_swagger_id,
            d.key AS method,
            raw_paths.path as path,
            regex_from_path(raw_paths.path) as regex,
            ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'group'::text) AS k8s_group,
            ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'version'::text) AS k8s_version,
            ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'kind'::text) AS k8s_kind,
            ( SELECT split_part((cat_tag.value ->> 0), '_'::text, 1) AS split_part
                FROM jsonb_array_elements((d.value -> 'tags'::text)) cat_tag(value)) AS category,
            (d.value ->> 'description'::text) AS description,
            (d.value ->> 'x-kubernetes-action'::text) AS x_kubernetes_action,
            ( SELECT string_agg(btrim((jsonstring.value)::text, '"'::text), ', '::text) AS string_agg
                 FROM jsonb_array_elements((d.value -> 'tags'::text)) jsonstring(value)) AS tags,
            ( SELECT string_agg(btrim((jsonstring.value)::text, '"'::text), ', '::text) AS string_agg
                 FROM jsonb_array_elements((d.value -> 'schemes'::text)) jsonstring(value)) AS schemes,
            (d.value -> 'consumes'::text) AS consumes,
            (d.value -> 'responses'::text) AS responses,
            (d.value -> 'parameters'::text) AS parameters,
            (lower((d.value ->> 'description'::text)) ~~ '%deprecated%'::text) AS deprecated
       FROM (raw_paths
             JOIN LATERAL jsonb_each(raw_paths.value) d(key, value) ON (true))
      ORDER BY (d.value ->> 'operationId'::text);
 #+END_SRC

 #+NAME: track api_operations
 #+BEGIN_SRC yaml :tangle ../hasura/migrations/150_view_api_operations.up.yaml
 - type: track_table
   args:
     schema: public
     name: api_operations
 #+END_SRC


 #+NAME: possible indexes
 #+BEGIN_SRC sql-mode :eval never
 create index api_operations_id on api_operations(id);
 create index api_operations_method on api_operations(method);
 create index api_operations_regexp on api_operations(regexp);
 #+END_SRC

*** api_operations_parameters view
**** operations_with_parameters view
 #+NAME: operations_with_parameters
 #+BEGIN_SRC sql-mode :eval never-export :tangle ../hasura/migrations/160_view_operations_with_parameters.up.sql
   CREATE OR REPLACE VIEW "public"."operations_with_parameters" AS 
     SELECT uuid_generate_v1() AS id,
            api_operations.id AS api_operations_id,
            api_operations.parameters
       FROM api_operations
      WHERE (api_operations.parameters IS NOT NULL)
      ORDER BY (uuid_generate_v1());
 #+END_SRC
 #+NAME: track operations_with_parameters
 #+BEGIN_SRC yaml :eval never-export :tangle ../hasura/migrations/160_view_operations_with_parameters.up.yaml
 - type: track_table
   args:
     schema: public
     name: operations_with_parameters
 #+END_SRC


**** api_operations real view

 #+NAME: api_operations_parameters view
 #+BEGIN_SRC sql-mode :eval no-export :tangle ../hasura/migrations/170_view_api_operations_parameters.up.sql
   -- DROP VIEW api_operations_parameters;
   CREATE OR REPLACE VIEW "public"."api_operations_parameters" AS 
     SELECT operations_with_parameters.api_operations_id,
            (param.entry ->> 'name'::text) AS name,
            (param.entry ->> 'in'::text) AS "in",
          replace(
            CASE
            WHEN ((param.entry ->> 'in'::text) = 'body'::text) 
              AND ((param.entry -> 'schema'::text) is not null)
                THEN ((param.entry -> 'schema'::text) ->> '$ref'::text)
            ELSE (param.entry ->> 'type'::text)
           END, '#/definitions/','') AS resource,
           -- CASE
           -- WHEN ((param.entry ->> 'in'::text) = 'body'::text) THEN ((param.entry -> 'schema'::text) ->> '$ref'::text)
           -- ELSE (param.entry ->> 'description'::text)
           -- END AS description,
           (param.entry ->> 'description'::text) AS description,
            CASE
            WHEN ((param.entry ->> 'required'::text) = 'true') THEN true
            ELSE false
           END AS required,
           CASE
            WHEN ((param.entry ->> 'uniqueItems'::text) = 'true') THEN true
            ELSE false
           END AS unique_items
           -- param.entry AS full_entry
       FROM operations_with_parameters,
            LATERAL jsonb_array_elements(operations_with_parameters.parameters) WITH ORDINALITY param(entry, index);
 #+END_SRC
 #+NAME: track api_operations_parameters
 #+BEGIN_SRC yaml :eval no-export :tangle ../hasura/migrations/170_view_api_operations_parameters.up.yaml
 - type: track_table
   args:
     schema: public
     name: api_operations_parameters
 #+END_SRC


*** api_operations_responses view
 #+NAME: Responses View
 #+BEGIN_SRC sql-mode :eval no-export :tangle ../hasura/migrations/180_view_api_operations_responses.up.sql
   CREATE OR REPLACE VIEW "public"."api_operations_responses" AS 
     SELECT uuid_generate_v1() AS id,
            api_operations.id AS api_operations_id,
              d.key AS code,
            (d.value ->> 'description'::text) AS description,
              replace(
              CASE
              WHEN (((d.value -> 'schema'::text) IS NOT NULL) AND (((d.value -> 'schema'::text) -> 'type'::text) IS NOT NULL))
                THEN ((d.value -> 'schema'::text) ->> 'type'::text)
              WHEN (((d.value -> 'schema'::text) IS NOT NULL) AND (((d.value -> 'schema'::text) -> '$ref'::text) IS NOT NULL))
               THEN ((d.value -> 'schema'::text) ->> '$ref'::text)
              ELSE NULL::text
             END, '#/definitions/','') AS resource
         FROM (api_operations
               JOIN LATERAL jsonb_each(api_operations.responses) d(key, value) ON (true))
        ORDER BY (uuid_generate_v1());
 #+END_SRC
 #+NAME: track api_operations_responses
 #+BEGIN_SRC yaml :tangle ../hasura/migrations/180_view_api_operations_responses.up.yaml
 - type: track_table
   args:
     schema: public
     name: api_operations_responses
 #+END_SRC

** Load Resource Views
*** api_resources view
 #+NAME: api_resources view
 #+BEGIN_SRC sql-mode :eval never-export :tangle ../hasura/migrations/190_view_api_resources.up.sql
 -- drop materialized view api_resources CASCADE;
 -- CREATE MATERIALIZED VIEW "public"."api_resources" AS 
 CREATE VIEW "public"."api_resources" AS 
  SELECT 
     uuid_generate_v1() AS id,
     raw_swaggers.id AS raw_swagger_id,
     d.key AS name,
     (d.value ->> 'type'::text) AS resource_type,
     (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'group'::text) AS k8s_group,
     (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'version'::text) AS k8s_version,
     (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'kind'::text) AS k8s_kind,
     ( SELECT string_agg(btrim((jsonstring.value)::text, '"'::text), ', '::text) AS string_agg
           FROM jsonb_array_elements((d.value -> 'required'::text)) jsonstring(value)) AS required_params,
     (d.value ->> 'required'::text) as required_params_text,
     (d.value -> 'properties'::text) AS properties,
     -- (raw_api_definitions.data ->> 'version'::text) AS source
     d.value
    FROM (raw_swaggers
      JOIN LATERAL jsonb_each((raw_swaggers.data -> 'definitions'::text)) d(key, value) ON (true))
   ORDER BY id;
 #+END_SRC
 #+NAME: track api_resources
 #+BEGIN_SRC yaml :tangle ../hasura/migrations/190_view_api_resources.up.yaml
 - type: track_table
   args:
     schema: public
     name: api_resources
 #+END_SRC

*** api_resources_fields view
 #+NAME: Properties View
 #+BEGIN_SRC sql-mode :eval never-export :tangle ../hasura/migrations/200_view_api_resources_fields.up.sql
   -- DROP VIEW api_resources_properties;
   -- DROP MATERIALIZED VIEW api_resources_properties;
   CREATE VIEW "public"."api_resources_fields" AS 
     SELECT api_resources.id AS type_id,
            d.key AS property,
            CASE
            WHEN ((d.value ->> 'type'::text) IS NULL) THEN 'subtype'::text
            ELSE (d.value ->> 'type'::text)
              END AS param_type,
            replace(
              CASE
              WHEN ((d.value ->> 'type'::text) = 'string'::text) THEN 'string'::text
              WHEN ((d.value ->> 'type'::text) IS NULL) THEN (d.value ->> '$ref'::text)
              WHEN ((d.value ->> 'type'::text) = 'array'::text)
               AND ((d.value -> 'items'::text) ->> 'type'::text) IS NULL
                THEN ((d.value -> 'items'::text) ->> '$ref'::text)
              WHEN ((d.value ->> 'type'::text) = 'array'::text)
               AND ((d.value -> 'items'::text) ->> '$ref'::text) IS NULL
                THEN ((d.value -> 'items'::text) ->> 'type'::text)
              ELSE 'integer'::text
              END, '#/definitions/','') AS param_kind,
            (d.value ->> 'description'::text) AS description,
            (d.value ->> 'format'::text) AS format,
            (d.value ->> 'x-kubernetes-patch-merge-key'::text) AS merge_key,
            (d.value ->> 'x-kubernetes-patch-strategy'::text) AS patch_strategy,
            -- CASE
            --   WHEN d.key is null THEN false
            --   WHEN (api_resources.required_params ? d.key) THEN true
            --   ELSE false
            --     END
            --   AS required,
            -- with param type also containing array, we don't need array as a boolean
            -- CASE
            -- WHEN ((d.value ->> 'type'::text) = 'array'::text) THEN true
            -- ELSE false
            --  END AS "array"
            d.value
       FROM (api_resources
             JOIN LATERAL jsonb_each(api_resources.properties) d(key, value) ON (true))
      ORDER BY api_resources.id;
 #+END_SRC
 #+NAME: track api_resources_fields
 #+BEGIN_SRC yaml :tangle ../hasura/migrations/200_view_api_resources_fields.up.yaml
 - type: track_table
   args:
     schema: public
     name: api_resources_fields
 #+END_SRC

** Create Over View
 #+NAME: over view
 #+BEGIN_SRC sql-mode :eval never-export :tangle ../hasura/migrations/210_view_over.up.sql
   -- drop materialized view api_resources CASCADE;
   -- CREATE MATERIALIZED VIEW "public"."api_resources" AS
   CREATE OR REPLACE VIEW "public"."over" AS
    SELECT
       -- JOIN raw_swaggers.id = o.raw_swagger_id
       -- JOIN raw_swaggers.id = r.raw_swagger_id
       -- JOIN o.id = op.api_operation_id
       -- JOIN r.id = rf.type_id
       -- where raw_swagger.id = 2 -- for now
       -- where raw_swagger.branch_or_tag = 'release-1.14' -- eventually
       o.operation_id,
       op.name as opname,
       op.required,
       -- op.unique,
       op.description as opdescription,
       --or.code, -- links via .resources
       --or.resource, -- links via .resources
      ---- JOIN op.name ==
       r.name as rname,
       r.k8s_group,
       r.k8s_version,
       r.k8s_kind,
       rf.property,
       rf.param_type,
       rf.param_kind,
       rf.description,
       rf.format,
       rf.merge_key,
       rf.patch_strategy
      FROM raw_swaggers rs,
        api_operations o,
        api_operations_parameters op,
        api_operations_responses resp,
        api_resources r,
        api_resources_fields rf
      WHERE rs.id = o.raw_swagger_id
        AND rs.id = r.raw_swagger_id
        AND o.id = op.api_operations_id
        AND r.id = rf.type_id
        -- AND rs.id = 1
     ORDER BY operation_id;
 #+END_SRC

 #+RESULTS: over view
 #+begin_src sql-mode
 #+end_src
 #+NAME: track over
 #+BEGIN_SRC yaml :tangle ../hasura/migrations/210_view_over.up.yaml
 - type: track_table
   args:
     schema: public
     name: over
 #+END_SRC

 #+BEGIN_SRC sql-mode
 select count(*) from "over";

 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
  count 
 -------
      0
 (1 row)

 #+end_src

** TODO Creating/Editing Views
* From meta.org_archive
  likely repeats here, including experiments with how to archive
#    -*- mode: org -*-

Archived entries from file /zfs/home/zz/ii/apisnoop_v3/org/meta.org

** TADA Remove interim 'operations with parameters' view            :ARCHIVE:
   CLOSED: [2019-08-09 Fri 00:03]
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-09 Fri 00:03
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :ARCHIVE_TODO: TADA
   :END:

 Archived entries from file /zfs/home/zz/ii/apisnoop_v3/org/meta.org

** TADA Finish the Over View
   CLOSED: [2019-08-09 Fri 00:03]
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-09 Fri 00:03
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :ARCHIVE_TODO: TADA
   :END:

 Archived entries from file /zfs/home/zz/ii/apisnoop_v3/org/meta.org

** TODO Creating/Editing Views
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-09 Fri 00:03
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :ARCHIVE_TODO: TODO
   :END:

** api_operations Materialized view
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-12 Mon 02:15
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_OLPATH: Operation Views/api_operations view
   :ARCHIVE_CATEGORY: meta
   :END:
 #+NAME: api_operations materialized view
 #+BEGIN_SRC sql-mode :eval never-export :notangle ../apps/hasura/migrations/150_view_api_operations.up.sql :results silent
   CREATE MATERIALIZED VIEW "public"."mat_api_operations" AS 
     SELECT raw_swaggers.id AS raw_swagger_id,
            paths.key AS path,
            regex_from_path(paths.key) as regex,
            d.key AS http_method,
            (d.value ->> 'x-kubernetes-action'::text) AS k8s_action,
            (d.value ->> 'operationId'::text) AS operation_id,
            ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'group'::text) AS k8s_group,
            ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'version'::text) AS k8s_version,
            ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'kind'::text) AS k8s_kind,
            (d.value ->> 'description'::text) AS description,
            (d.value -> 'consumes'::text) AS consumes,
            (d.value -> 'responses'::text) AS responses,
            (d.value -> 'parameters'::text) AS parameters,
            (lower((d.value ->> 'description'::text)) ~~ '%deprecated%'::text) AS deprecated,
            split_part((cat_tag.value ->> 0), '_'::text, 1) AS category,
            string_agg(btrim((jsonstring.value)::text, '"'::text), ', '::text) AS tags,
            string_agg(btrim((schemestring.value)::text, '"'::text), ', '::text) AS schemes,
            CASE
             WHEN (d.value ->> 'x-kubernetes-action'::text) IN ('get', 'list', 'proxy') THEN 'get'
             WHEN (d.value ->> 'x-kubernetes-action'::text) IN ('deleteCollection', 'delete', 'deletecollection') THEN 'delete'
             WHEN (d.value ->> 'x-kubernetes-action'::text) IN ('watch', 'watchlist', 'watch') THEN 'watch'
             WHEN (d.value ->> 'x-kubernetes-action'::text) IN ('create', 'post') THEN 'post'
             WHEN (d.value ->> 'x-kubernetes-action'::text) IN ( 'update', 'put' ) THEN 'put'
             WHEN (d.value ->> 'x-kubernetes-action'::text) = 'patch' THEN 'patch'
             WHEN (d.value ->> 'x-kubernetes-action'::text) = 'connect' THEN 'connect'
            ELSE NULL
              END as event_verb
       FROM raw_swaggers
       , jsonb_each((raw_swaggers.data -> 'paths'::text)) paths(key, value)
       , jsonb_each(paths.value) d(key, value)
       , jsonb_array_elements((d.value -> 'tags'::text)) cat_tag(value)
       , jsonb_array_elements((d.value -> 'tags'::text)) jsonstring(value)
       , jsonb_array_elements((d.value -> 'schemes'::text)) schemestring(value)
      GROUP BY raw_swaggers.id, paths.key, d.key, d.value, cat_tag.value
      ORDER BY paths.key;
 #+END_SRC


 #+BEGIN_SRC sql-mode
   CREATE INDEX on mat_api_operations (operation_id);
   CREATE INDEX on mat_api_operations (regex);
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
 CREATE INDEX
 #+end_src

 #+NAME: api_operations indexes the raw_swagger
 #+BEGIN_SRC sql-mode :tangle ../apps/hasura/migrations/100_table_raw_swaggers.up.sql :results silent
   -- CREATE INDEX idx_swagger_gin_paths ON raw_swaggers USING GIN ((data->>'paths'));
   -- CREATE INDEX idx_swagger_btree_paths ON raw_swaggers USING BTREE ((data->>'paths'));
   -- CREATE INDEX idx_swagger_hash_paths ON raw_swaggers USING HASH ((data->>'paths'))
        -- api_operations view:
        --  , jsonb_each((raw_swaggers.data -> 'paths'::text)) paths(key, value)
        --  , jsonb_each(paths.value) d(key, value)
        --  , jsonb_array_elements((d.value -> 'tags'::text)) cat_tag(value)
        --  , jsonb_array_elements((d.value -> 'tags'::text)) jsonstring(value)
        --  , jsonb_array_elements((d.value -> 'schemes'::text)) schemestring(value)
        -- GROUP BY raw_swaggers.id, paths.key, d.key, d.value, cat_tag.value
        -- ORDER BY paths.key;
        -- api_resources view:
        --   , jsonb_each((raw_swaggers.data -> 'definitions'::text)) d(key, value)
        --   , jsonb_array_elements((d.value -> 'required'::text)) reqstring(value)
        -- GROUP BY raw_swaggers.id, d.key, d.value;
   -- CREATE INDEX idx_swagger_X ON raw_swagger USING GIN ((jsb->‘X’));
   -- CREATE INDEX idx_swagger_X ON raw_swagger USING BTREE ((jsb->>‘X’));
   -- CREATE INDEX idx_swagger_X ON raw_swagger USING HASH ((jsb->>‘X’))
   #+END_SRC

   #+RESULTS: api_operations indexes the raw_swagger
   #+begin_src sql-mode
       event_verb    
   ------------------
    create
    delete
    deletecollection
    get
    list
    patch
    update
   (7 rows)

   #+end_src

 #
 #+NAME: uniq audit entry verbs raw
 #+BEGIN_SRC shell
 cd /tmp/apisnoop-ci-kubernetes-e2e-gci-gce-11349620722877112346arl78tw
 cat audit.log | jq .verb | sort | uniq
 #+END_SRC

 #+RESULTS: uniq audit entry verbs raw
 #+begin_EXAMPLE
 "abcd"
 "create"
 "delete"
 "deletecollection"
 "get"
 "list"
 "patch"
 "post"
 "update"
 "watch"
 #+end_EXAMPLE


 #+NAME: Double check operation_id verbs
 #+BEGIN_SRC sql-mode
 SELECT DISTINCT k8s_action, http_method
 FROM api_operations
 order by k8s_action;
 #+END_SRC

 #+RESULTS: Double check operation_id verbs
 #+begin_src sql-mode
     k8s_action    | http_method 
 ------------------+-------------
  connect          | delete
  connect          | get
  connect          | head
  connect          | options
  connect          | patch
  connect          | post
  connect          | put
  delete           | delete
  deletecollection | delete
  get              | get
  list             | get
  patch            | patch
  post             | post
  put              | put
  watch            | get
  watchlist        | get
                   | get
 (17 rows)

 #+end_src
 #+NAME: Double check operation_id verbs

 #+NAME: method = options
 #+BEGIN_SRC sql-mode
 SELECT operation_id, k8s_action, http_method, path
 FROM api_operations
 where http_method like 'options';
 #+END_SRC

 #+RESULTS: method = options
 #+begin_src sql-mode
                     operation_id                    | k8s_action | http_method |                            path                             
 ----------------------------------------------------+------------+-------------+-------------------------------------------------------------
  connectCoreV1OptionsNamespacedPodProxy             | connect    | options     | /api/v1/namespaces/{namespace}/pods/{name}/proxy
  connectCoreV1OptionsNamespacedPodProxyWithPath     | connect    | options     | /api/v1/namespaces/{namespace}/pods/{name}/proxy/{path}
  connectCoreV1OptionsNamespacedServiceProxy         | connect    | options     | /api/v1/namespaces/{namespace}/services/{name}/proxy
  connectCoreV1OptionsNamespacedServiceProxyWithPath | connect    | options     | /api/v1/namespaces/{namespace}/services/{name}/proxy/{path}
  connectCoreV1OptionsNodeProxy                      | connect    | options     | /api/v1/nodes/{name}/proxy
  connectCoreV1OptionsNodeProxyWithPath              | connect    | options     | /api/v1/nodes/{name}/proxy/{path}
 (6 rows)

 #+end_src

 #+NAME: Double check audit_entries verbs / ops
 #+BEGIN_SRC sql-mode
 explain SELECT DISTINCT event_verb
 FROM audit_events;
 -- order by event_verb;
 #+END_SRC

 #+RESULTS: Double check audit_entries verbs / ops
 #+begin_src sql-mode
                                                                    QUERY PLAN                                                                   
 ------------------------------------------------------------------------------------------------------------------------------------------------
  Unique  (cost=18311202947114.33..18320060226114.33 rows=313532 width=32)
    ->  Sort  (cost=18311202947114.33..18315631586614.33 rows=1771455800000 width=32)
          Sort Key: ((raw.data ->> 'verb'::text))
          ->  Nested Loop  (cost=8857888750630.28..17654133088298.60 rows=1771455800000 width=32)
                Join Filter: ((raw.data ->> 'requestURI'::text) ~ ops.regex)
                ->  Seq Scan on raw_audit_events raw  (cost=0.00..50648.32 rows=313532 width=1091)
                ->  Materialize  (cost=8857888750630.28..9027707225240.28 rows=1130000000 width=32)
                      ->  Subquery Scan on ops  (cost=8857888750630.28..9027693850630.28 rows=1130000000 width=32)
                            ->  GroupAggregate  (cost=8857888750630.28..9027682550630.28 rows=1130000000 width=549)
                                  Group Key: paths.key, raw_swaggers.id, d.key, d.value, cat_tag.value
                                  ->  Sort  (cost=8857888750630.28..8886138750630.28 rows=11300000000000 width=132)
                                        Sort Key: paths.key, raw_swaggers.id, d.key, d.value, cat_tag.value
                                        ->  Nested Loop  (cost=0.02..228282828281.32 rows=11300000000000 width=132)
                                              ->  Nested Loop  (cost=0.02..2282828281.32 rows=113000000000 width=132)
                                                    ->  Nested Loop  (cost=0.01..22828281.31 rows=1130000000 width=132)
                                                          ->  Nested Loop  (cost=0.01..228281.31 rows=11300000 width=100)
                                                                ->  Nested Loop  (cost=0.01..2281.30 rows=113000 width=68)
                                                                      ->  Seq Scan on raw_swaggers  (cost=0.00..21.30 rows=1130 width=36)
                                                                      ->  Function Scan on jsonb_each paths  (cost=0.01..1.00 rows=100 width=64)
                                                                ->  Function Scan on jsonb_each d  (cost=0.00..1.00 rows=100 width=64)
                                                          ->  Function Scan on jsonb_array_elements cat_tag  (cost=0.01..1.00 rows=100 width=32)
                                                    ->  Function Scan on jsonb_array_elements jsonstring  (cost=0.01..1.00 rows=100 width=0)
                                              ->  Function Scan on jsonb_array_elements schemestring  (cost=0.01..1.00 rows=100 width=0)
 (23 rows)

 #+end_src


 #+RESULTS: api_operations view
 #+begin_src sql-mode
 CREATE VIEW
 #+end_src

 #+NAME: track api_operations
 #+BEGIN_SRC yaml :tangle ../apps/hasura/migrations/150_view_api_operations.up.yaml
 - type: track_table
   args:
     schema: public
     name: api_operations
 #+END_SRC


 #+NAME: possible indexes
 #+BEGIN_SRC sql-mode :eval never
 create index api_operations_id on api_operations(id);
 create index api_operations_method on api_operations(method);
 create index api_operations_regexp on api_operations(regexp);
 #+END_SRC

** TADA run query on count of audit_events whose operation_id is null.  hope for <50k
   CLOSED: [2019-08-14 Wed 23:51]
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-14 Wed 23:51
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :ARCHIVE_TODO: TADA
   :END:

** TADA update zraw_audit_events now that mapping is correct
   CLOSED: [2019-08-14 Wed 23:51]
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-14 Wed 23:51
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :ARCHIVE_TODO: TADA
   :END:

** TADA Adjust api_operations_material with correct mapping of event verb
   CLOSED: [2019-08-14 Wed 23:52]
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-14 Wed 23:52
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :ARCHIVE_TODO: TADA
   :END:
   Our original event_verb assumed that the audit_event would only have the http request verbs available.

   Now that we have the zraw_audit_events table, though, we can see this is not the case.
   #+NAME:Distinct Event Verbs in audit_events
   #+BEGIN_SRC sql-mode
   SELECT DISTINCT event_verb
   FROM zraw_audit_events;
   #+END_SRC
  
   #+RESULTS: Distinct Event Verbs in audit_events
   #+begin_src sql-mode
       event_verb    
   ------------------
    list
    deletecollection
    delete
    update
    get
    create
    post
    abcd
    watch
    patch
   (10 rows)
   #+end_src
  
   Our api_operations_material reduces a number of possible verbs into the https request verbs
   #+NAME: event verbs and k8s_actions in api_operations_material
   #+BEGIN_SRC sql-mode
   SELECT DISTINCT k8s_action, event_verb
   FROM api_operations_material
   ORDER BY event_verb;
   #+END_SRC

   #+RESULTS: event verbs and k8s_actions in api_operations_material
   #+begin_src sql-mode
       k8s_action    | event_verb 
   ------------------+------------
    connect          | connect
    delete           | delete
    deletecollection | delete
    get              | get
    list             | get
    patch            | patch
    post             | post
    put              | put
    watchlist        | watch
    watch            | watch
                     | 
   (11 rows)
   #+end_src

  This means that audit_events are returning null because these verbs have been absorbed in our mapping incorrectly.  
  For example, list and deleteCollection will return null even though there's a direct connect between the audit event verb and the api_operations k8s_action.
  The two verbs on the audit_event side that don't fully map are =create= and =update= 
  
  We could likely see what their mapping to k8s_action should be by checking their request_uri or request object
 
  #+NAME: request_uri of create audit_events
  #+BEGIN_SRC sql-mode
    SELECT
      request_uri,
      event_verb FROM zraw_audit_events WHERE
      event_verb = 'create'
    LIMIT
      10;

  #+END_SRC

  #+RESULTS: request_uri of create audit_events
  #+begin_src sql-mode
                                         request_uri                                        | event_verb 
  ------------------------------------------------------------------------------------------+------------
   /apis/rbac.authorization.k8s.io/v1beta1/namespaces/node-lease-test-6991/rolebindings     | create
   /apis/authorization.k8s.io/v1beta1/subjectaccessreviews                                  | create
   /api/v1/namespaces/provisioning-62/pods                                                  | create
   /apis/authorization.k8s.io/v1beta1/subjectaccessreviews                                  | create
   /api/v1/namespaces/nettest-1762/pods/host-test-container-pod/binding                     | create
   /api/v1/namespaces/kube-system/configmaps                                                | create
   /apis/autoscaling/v1/namespaces/horizontal-pod-autoscaling-3029/horizontalpodautoscalers | create
   /api/v1/namespaces/volumemode-6821/secrets                                               | create
   /api/v1/namespaces/deployment-2887/pods/test-cleanup-controller-2pkb8/binding            | create
   /apis/authorization.k8s.io/v1beta1/subjectaccessreviews                                  | create
  (10 rows)

  #+end_src

  Never mind!

 It makes sense to me that 'create' would be a post and update a put.  The problem is that post is already present in both k8s_action and event_verb...so we can't do a one to one match.  I think we need to do an ANY on the event verb array.  so the api_operations_material event_verb wold be ['create', 'post'] .  I had an issue doing this, and so made it a comma separated string.  We can then update our join clause as a like

 I've updated the api_operations for that.  Then we'll update our zraw_audit_events to map on any instead.

 So we can now see our distinct event_verbs in the api_operations_material view
 #+NAME: Distinct Event Verbs in api_operations_material
 #+BEGIN_SRC sql-mode
 select distinct event_verb from api_operations_material;
 #+END_SRC

 #+RESULTS: Distinct Event Verbs in api_operations_material
 #+begin_src sql-mode
      event_verb     
 --------------------
 
  {watch}
  {post,create}
  {get}
  {connect}
  {patch}
  {list}
  {deletecollection}
  {put,update}
 (9 rows)

 #+end_src

 Now we need to update our zraw_audit_events_view remaking its operation_id
 #+NAME: Update zraw_audit_events
 #+BEGIN_SRC sql-mode 
   UPDATE zraw_audit_events AS raw
   SET operation_id = ops.operation_id
   FROM api_operations_material ops
   WHERE
       ops.raw_swagger_id = 1
       AND raw.data ->> 'verb' = ANY(ops.event_verb)
       AND raw.data ->> 'requestURI' ~ ops.regex;
 #+END_SRC


  
** TADA Indexed raw_audit_events                                                                                                                                                       
   CLOSED: [2019-08-14 Wed 23:52]
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-14 Wed 23:52
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :ARCHIVE_TODO: TADA
   :END:
**** What does Success look like?                                                                                                                                                  
  - figure out how to get a count on a where clause                                                                                                                                
  - figure out how to get a distinct on something.                                                                                                                                 
  -  Being able to accurately fill out the hit counts in this query: https://hackmd.io/mnjYC64uQ1eKTr6PIXp5dw?view                                                                 
**** what's the itching confusion?                                                                                                                                                 
  - Proper way to index so that we can do a distinct                                                                                                                               
  - we have to avoid a table scan. Must have index for any place where we are trying to reference a row.                                                                           
    -  e.g. if table says `WHERE audit_event.parameter LIKE '%podspec%' we would need an index on audiet_event.parameter                                                           
  - api_operations: need to calculate, and leave as entry, 'audit_event_verb' (whetever its called) so we have a direct match later on audit_event table.                          
 ◉ FOOTNOTES...                                                                                                                                                 
**** Experiment
     What if we just load the event_verb and audit_id as distint columsn when the table is first being populated, since we are pulling from a temp table anyway?
    
     I can confirm it works with auditId(audit_id), verb(event_verb), and requestURI(request_uri).
    
     So we are putting the load of the work onto the population of data, instead of on the query, and this is happening from a raw file--and so it is much quicker..  
     Now, I am wondering if we can add operationID too, using a JOIN ON regex and verb.
     This requires setting up our api_operations a bit differently.
    
     We updated api_operations to include an event_verb, and should be able to run a query where we join the table based on the verb and regex matching.  but the query was hanging, likely because it was taking way too long to walk the tree of two un-indexed views.  Our strategythen is to amek both materialized views, that we can then create indexes on, to then make the joins much faster.
*****  Create Table
     So we'll make a table that is expecting audit_id and event_verb 
  #+NAME: raw_audit_events test
  #+BEGIN_SRC sql-mode :notangle ../apps/hasura/migrations/220_table_raw_audit_events.up.sql :results silent
  CREATE TABLE zraw_audit_events (
      id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      ingested_at timestamp DEFAULT CURRENT_TIMESTAMP,
      bucket text,
      job text,
      data jsonb NOT NULL,
      audit_id text,
      event_verb text,
      request_uri text,
      operation_id text
  );
  #+END_SRC
***** Iteration Loop
    
  #+NAME: Confirm Table Exists
  #+BEGIN_SRC sql-mode
    \d zraw_audit_events;
    -- delete from raw_audit_events;
  #+END_SRC

  #+RESULTS: Confirm Table Exists
  #+begin_src sql-mode
                                     Table "public.zraw_audit_events"
      Column    |            Type             | Collation | Nullable |             Default              
  --------------+-----------------------------+-----------+----------+----------------------------------
   id           | integer                     |           | not null | generated by default as identity
   ingested_at  | timestamp without time zone |           |          | CURRENT_TIMESTAMP
   bucket       | text                        |           |          | 
   job          | text                        |           |          | 
   data         | jsonb                       |           | not null | 
   audit_id     | text                        |           |          | 
   event_verb   | text                        |           |          | 
   request_uri  | text                        |           |          | 
   operation_id | text                        |           |          | 
  Indexes:
      "zraw_audit_events_pkey" PRIMARY KEY, btree (id)

  #+end_src

  #+NAME: Drop Table
  #+BEGIN_SRC sql-mode :results silent
  DROP TABLE IF EXISTS zraw_audit_events;
  #+END_SRC


  #+NAME: Test that new columns Work
  #+BEGIN_SRC sql-mode
  SELECT event_verb, audit_id, request_uri
  FROM zraw_audit_events
  LIMIT 8;
  #+END_SRC

  #+RESULTS: Test that new columns Work
  #+begin_src sql-mode
  ERROR:  relation "zraw_audit_events" does not exist
  LINE 2: FROM zraw_audit_events
               ^
  #+end_src

***** Load Audit Events
     
      We need to match our event to an operation ID.
      An operation ID is unique on raw_swagger_id, http method, and regex.
      So we should try to match the vent on the same three.
      raw.data ->> 'requestURI' ~ ops.regex
      raw.data ->> 'verb' = 
      ops.raw_swagger_id = 1
  #+NAME: experimental load_audit_events.sh
  #+BEGIN_SRC shell :var AUDIT_LOG="../data/artifacts/ci-kubernetes-e2e-gci-gce/1134962072287711234/combined-audit.log"

   BUCKET='ci-kubernetes-e2e-gci-gce'
   JOB='1134962072287711234'
   SQL="
   CREATE TEMPORARY TABLE raw_audit_events_import (data jsonb not null) ;
   copy raw_audit_events_import (data)
   FROM STDIN (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');
   INSERT INTO zraw_audit_events(data, bucket, job, audit_id, event_verb, request_uri, operation_id)
   SELECT raw.data, '$BUCKET', '$JOB', (raw.data ->> 'auditID'), (raw.data ->> 'verb'), (raw.data ->> 'requestURI'), ops.operation_id
   FROM raw_audit_events_import raw
   LEFT JOIN api_operations_material ops ON
        ops.raw_swagger_id = 1
        AND raw.data ->> 'verb' = ops.event_verb
        AND raw.data ->> 'requestURI' ~ ops.regex;
   "
   cat $AUDIT_LOG | psql -c "$SQL" 2>&1
   date
  #+END_SRC

  #+RESULTS: experimental load_audit_events.sh
  #+begin_EXAMPLE
  INSERT 0 313431
  Mon Aug 12 22:41:18 UTC 2019
  #+end_EXAMPLE
  ** event_verb_to_http_method

  
  #+BEGIN_SRC sql-mode
 SELECT DISTINCT audit_id, operation_id
 FROM zraw_audit_events;
  #+END_SRC
 
  #+NAME: Distinct Key
  #+BEGIN_SRC sql-mode
 select distinct data->'requestObject'->>'kind' as keys
 from zraw_audit_events
 order by keys;
  #+END_SRC

  #+RESULTS: Distinct Keys
  #+begin_src sql-mode
                keys              
  --------------------------------
   APIService
   Binding
   CertificateSigningRequest
   ClusterRole
   ClusterRoleBinding
   ControllerRevision
   CronJob
   CSIDriver
   CSINode
   CustomResourceDefinition
   DaemonSet
   DeleteOptions
   Deployment
   DeploymentRollback
   Endpoints
   HorizontalPodAutoscaler
   Job
   LimitRange
   MutatingWebhookConfiguration
   Namespace
   Node
   PersistentVolume
   PersistentVolumeClaim
   Pod
   PodDisruptionBudget
   PodSecurityPolicy
   PodTemplate
   PriorityClass
   ReplicaSet
   ReplicationController
   ResourceQuota
   Role
   RoleBinding
   RuntimeClass
   Scale
   Service
   ServiceAccount
   StatefulSet
   StorageClass
   SubjectAccessReview
   ValidatingWebhookConfiguration
   VolumeAttachment
  (43 rows)

  #+end_src

 
  - we did a join, and got 50k results, which seemed too small.
  - the join is based on matching regex, event_verb, and raw_swagger_id 
  - raw events is 300k, it shoudl be closer to that?
  - what is the reason for nulls?  how often is i
  #+NAME: Audit_events without matching operations: sample
  #+BEGIN_SRC sql-mode
    SELECT
      distinct event_verb
    FROM
      zraw_audit_events
    LIMIT 50;
  #+END_SRC

  #+RESULTS: Audit_events without matching operations: sample
  #+begin_src sql-mode
      event_verb    
  ------------------
   list
   deletecollection
   delete
   update
   get
   create
   post
   abcd
   watch
   patch
  (10 rows)

  #+end_src

  #+BEGIN_SRC sql-mode
    SELECT
      path, regex
    FROM
      api_operations_material 
     WHERE
       path LIKE '/apis/authorization.k8s.io/v1beta1/subjectaccessreviews%';

  #+END_SRC
 
  #+BEGIN_SRC sql-mode
 select distinct param_kind from api_resources_fields order by param_kind;
 -- select * from api_resources_fields where param_kind ilike '%PodSpec';
  #+END_SRC


  #+RESULTS:
  #+begin_src sql-mode
                                             param_kind                                            
  -------------------------------------------------------------------------------------------------
   integer
   io.k8s.api.admissionregistration.v1beta1.MutatingWebhookConfiguration
   io.k8s.api.admissionregistration.v1beta1.RuleWithOperations
   io.k8s.api.admissionregistration.v1beta1.ValidatingWebhookConfiguration
   io.k8s.api.admissionregistration.v1beta1.WebhookClientConfig
   io.k8s.api.admissionregistration.v1.MutatingWebhookConfiguration
   io.k8s.api.admissionregistration.v1.RuleWithOperations
   io.k8s.api.admissionregistration.v1.ValidatingWebhookConfiguration
   io.k8s.api.admissionregistration.v1.WebhookClientConfig
   io.k8s.api.apps.v1beta1.ControllerRevision
   io.k8s.api.apps.v1beta1.Deployment
   io.k8s.api.apps.v1beta1.DeploymentStrategy
   io.k8s.api.apps.v1beta1.RollbackConfig
   io.k8s.api.apps.v1beta1.StatefulSet
   io.k8s.api.apps.v1beta1.StatefulSetCondition
   io.k8s.api.apps.v1beta1.StatefulSetUpdateStrategy
   io.k8s.api.apps.v1beta2.ControllerRevision
   io.k8s.api.apps.v1beta2.DaemonSet
   io.k8s.api.apps.v1beta2.DaemonSetCondition
   io.k8s.api.apps.v1beta2.DaemonSetUpdateStrategy
   io.k8s.api.apps.v1beta2.Deployment
   io.k8s.api.apps.v1beta2.DeploymentStrategy
   io.k8s.api.apps.v1beta2.ReplicaSet
   io.k8s.api.apps.v1beta2.ReplicaSetCondition
   io.k8s.api.apps.v1beta2.StatefulSet
   io.k8s.api.apps.v1beta2.StatefulSetCondition
   io.k8s.api.apps.v1beta2.StatefulSetUpdateStrategy
   io.k8s.api.apps.v1.ControllerRevision
   io.k8s.api.apps.v1.DaemonSet
   io.k8s.api.apps.v1.DaemonSetCondition
   io.k8s.api.apps.v1.DaemonSetUpdateStrategy
   io.k8s.api.apps.v1.Deployment
   io.k8s.api.apps.v1.DeploymentStrategy
   io.k8s.api.apps.v1.ReplicaSet
   io.k8s.api.apps.v1.ReplicaSetCondition
   io.k8s.api.apps.v1.StatefulSet
   io.k8s.api.apps.v1.StatefulSetCondition
   io.k8s.api.apps.v1.StatefulSetUpdateStrategy
   io.k8s.api.auditregistration.v1alpha1.AuditSink
   io.k8s.api.auditregistration.v1alpha1.Policy
   io.k8s.api.auditregistration.v1alpha1.Webhook
   io.k8s.api.auditregistration.v1alpha1.WebhookClientConfig
   io.k8s.api.auditregistration.v1alpha1.WebhookThrottleConfig
   io.k8s.api.authentication.v1beta1.TokenReviewSpec
   io.k8s.api.authentication.v1beta1.TokenReviewStatus
   io.k8s.api.authentication.v1.BoundObjectReference
   io.k8s.api.authentication.v1.TokenRequestSpec
   io.k8s.api.authentication.v1.TokenRequestStatus
   io.k8s.api.authentication.v1.TokenReviewSpec
   io.k8s.api.authentication.v1.TokenReviewStatus
   io.k8s.api.authorization.v1beta1.NonResourceRule
   io.k8s.api.authorization.v1beta1.ResourceRule
   io.k8s.api.authorization.v1beta1.SelfSubjectAccessReviewSpec
   io.k8s.api.authorization.v1beta1.SelfSubjectRulesReviewSpec
   io.k8s.api.authorization.v1beta1.SubjectAccessReviewSpec
   io.k8s.api.authorization.v1beta1.SubjectAccessReviewStatus
   io.k8s.api.authorization.v1beta1.SubjectRulesReviewStatus
   io.k8s.api.authorization.v1.NonResourceRule
   io.k8s.api.authorization.v1.ResourceRule
   io.k8s.api.authorization.v1.SelfSubjectAccessReviewSpec
   io.k8s.api.authorization.v1.SelfSubjectRulesReviewSpec
   io.k8s.api.authorization.v1.SubjectAccessReviewSpec
   io.k8s.api.authorization.v1.SubjectAccessReviewStatus
   io.k8s.api.authorization.v1.SubjectRulesReviewStatus
   io.k8s.api.autoscaling.v1.CrossVersionObjectReference
   io.k8s.api.autoscaling.v1.HorizontalPodAutoscaler
   io.k8s.api.autoscaling.v2beta1.CrossVersionObjectReference
   io.k8s.api.autoscaling.v2beta1.ExternalMetricSource
   io.k8s.api.autoscaling.v2beta1.ExternalMetricStatus
   io.k8s.api.autoscaling.v2beta1.HorizontalPodAutoscaler
   io.k8s.api.autoscaling.v2beta1.HorizontalPodAutoscalerCondition
   io.k8s.api.autoscaling.v2beta1.MetricSpec
   io.k8s.api.autoscaling.v2beta1.MetricStatus
   io.k8s.api.autoscaling.v2beta1.ObjectMetricSource
   io.k8s.api.autoscaling.v2beta1.ObjectMetricStatus
   io.k8s.api.autoscaling.v2beta1.PodsMetricSource
   io.k8s.api.autoscaling.v2beta1.PodsMetricStatus
   io.k8s.api.autoscaling.v2beta1.ResourceMetricSource
   io.k8s.api.autoscaling.v2beta1.ResourceMetricStatus
   io.k8s.api.autoscaling.v2beta2.CrossVersionObjectReference
   io.k8s.api.autoscaling.v2beta2.ExternalMetricSource
   io.k8s.api.autoscaling.v2beta2.ExternalMetricStatus
   io.k8s.api.autoscaling.v2beta2.HorizontalPodAutoscaler
   io.k8s.api.autoscaling.v2beta2.HorizontalPodAutoscalerCondition
   io.k8s.api.autoscaling.v2beta2.MetricIdentifier
   io.k8s.api.autoscaling.v2beta2.MetricSpec
   io.k8s.api.autoscaling.v2beta2.MetricStatus
   io.k8s.api.autoscaling.v2beta2.MetricTarget
   io.k8s.api.autoscaling.v2beta2.MetricValueStatus
   io.k8s.api.autoscaling.v2beta2.ObjectMetricSource
   io.k8s.api.autoscaling.v2beta2.ObjectMetricStatus
   io.k8s.api.autoscaling.v2beta2.PodsMetricSource
   io.k8s.api.autoscaling.v2beta2.PodsMetricStatus
   io.k8s.api.autoscaling.v2beta2.ResourceMetricSource
   io.k8s.api.autoscaling.v2beta2.ResourceMetricStatus
   io.k8s.api.batch.v1beta1.CronJob
   io.k8s.api.batch.v1beta1.JobTemplateSpec
   io.k8s.api.batch.v1.Job
   io.k8s.api.batch.v2alpha1.CronJob
   io.k8s.api.batch.v2alpha1.JobTemplateSpec
   io.k8s.api.certificates.v1beta1.CertificateSigningRequest
   io.k8s.api.coordination.v1beta1.Lease
   io.k8s.api.coordination.v1.Lease
   io.k8s.api.core.v1.Affinity
   io.k8s.api.core.v1.AWSElasticBlockStoreVolumeSource
   io.k8s.api.core.v1.AzureDiskVolumeSource
   io.k8s.api.core.v1.AzureFileVolumeSource
   io.k8s.api.core.v1.CephFSVolumeSource
   io.k8s.api.core.v1.CinderVolumeSource
   io.k8s.api.core.v1.ComponentStatus
   io.k8s.api.core.v1.ConfigMap
   io.k8s.api.core.v1.ConfigMapVolumeSource
   io.k8s.api.core.v1.Container
   io.k8s.api.core.v1.ContainerPort
   io.k8s.api.core.v1.ContainerState
   io.k8s.api.core.v1.CSIVolumeSource
   io.k8s.api.core.v1.DownwardAPIVolumeSource
   io.k8s.api.core.v1.EmptyDirVolumeSource
   io.k8s.api.core.v1.Endpoints
   io.k8s.api.core.v1.EnvFromSource
   io.k8s.api.core.v1.EnvVar
   io.k8s.api.core.v1.EnvVarSource
   io.k8s.api.core.v1.EphemeralContainer
   io.k8s.api.core.v1.Event
   io.k8s.api.core.v1.EventSeries
   io.k8s.api.core.v1.EventSource
   io.k8s.api.core.v1.FCVolumeSource
   io.k8s.api.core.v1.FlexVolumeSource
   io.k8s.api.core.v1.FlockerVolumeSource
   io.k8s.api.core.v1.GCEPersistentDiskVolumeSource
   io.k8s.api.core.v1.GitRepoVolumeSource
   io.k8s.api.core.v1.GlusterfsVolumeSource
   io.k8s.api.core.v1.HostAlias
   io.k8s.api.core.v1.HostPathVolumeSource
   io.k8s.api.core.v1.HTTPHeader
   io.k8s.api.core.v1.ISCSIVolumeSource
   io.k8s.api.core.v1.Lifecycle
   io.k8s.api.core.v1.LimitRange
   io.k8s.api.core.v1.LimitRangeItem
   io.k8s.api.core.v1.LocalObjectReference
   io.k8s.api.core.v1.Namespace
   io.k8s.api.core.v1.NFSVolumeSource
   io.k8s.api.core.v1.Node
   io.k8s.api.core.v1.NodeSelectorTerm
   io.k8s.api.core.v1.ObjectFieldSelector
   io.k8s.api.core.v1.ObjectReference
   io.k8s.api.core.v1.PersistentVolume
   io.k8s.api.core.v1.PersistentVolumeClaim
   io.k8s.api.core.v1.PersistentVolumeClaimVolumeSource
   io.k8s.api.core.v1.PhotonPersistentDiskVolumeSource
   io.k8s.api.core.v1.Pod
   io.k8s.api.core.v1.PodAffinityTerm
   io.k8s.api.core.v1.PodDNSConfig
   io.k8s.api.core.v1.PodReadinessGate
   io.k8s.api.core.v1.PodSecurityContext
   io.k8s.api.core.v1.PodTemplate
   io.k8s.api.core.v1.PodTemplateSpec
   io.k8s.api.core.v1.PortworxVolumeSource
   io.k8s.api.core.v1.Probe
   io.k8s.api.core.v1.ProjectedVolumeSource
   io.k8s.api.core.v1.QuobyteVolumeSource
   io.k8s.api.core.v1.RBDVolumeSource
   io.k8s.api.core.v1.ReplicationController
   io.k8s.api.core.v1.ReplicationControllerCondition
   io.k8s.api.core.v1.ResourceFieldSelector
   io.k8s.api.core.v1.ResourceQuota
   io.k8s.api.core.v1.ResourceRequirements
   io.k8s.api.core.v1.ScaleIOVolumeSource
   io.k8s.api.core.v1.Secret
   io.k8s.api.core.v1.SecretReference
   io.k8s.api.core.v1.SecretVolumeSource
   io.k8s.api.core.v1.SecurityContext
   io.k8s.api.core.v1.SELinuxOptions
   io.k8s.api.core.v1.Service
   io.k8s.api.core.v1.ServiceAccount
   io.k8s.api.core.v1.StorageOSVolumeSource
   io.k8s.api.core.v1.Toleration
   io.k8s.api.core.v1.TopologySelectorTerm
   io.k8s.api.core.v1.TopologySpreadConstraint
   io.k8s.api.core.v1.Volume
   io.k8s.api.core.v1.VolumeDevice
   io.k8s.api.core.v1.VolumeMount
   io.k8s.api.core.v1.VolumeProjection
   io.k8s.api.core.v1.VsphereVirtualDiskVolumeSource
   io.k8s.api.events.v1beta1.Event
   io.k8s.api.events.v1beta1.EventSeries
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceColumnDefinition
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceConversion
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceDefinition
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceDefinitionCondition
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceDefinitionNames
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceDefinitionSpec
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceDefinitionStatus
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceDefinitionVersion
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceSubresources
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceValidation
   io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.v1beta1.WebhookClientConfig
   io.k8s.api.extensions.v1beta1.AllowedCSIDriver
   io.k8s.api.extensions.v1beta1.AllowedFlexVolume
   io.k8s.api.extensions.v1beta1.AllowedHostPath
   io.k8s.api.extensions.v1beta1.DaemonSet
   io.k8s.api.extensions.v1beta1.DaemonSetCondition
   io.k8s.api.extensions.v1beta1.DaemonSetUpdateStrategy
   io.k8s.api.extensions.v1beta1.Deployment
   io.k8s.api.extensions.v1beta1.DeploymentStrategy
   io.k8s.api.extensions.v1beta1.FSGroupStrategyOptions
   io.k8s.api.extensions.v1beta1.HostPortRange
   io.k8s.api.extensions.v1beta1.HTTPIngressPath
   io.k8s.api.extensions.v1beta1.IDRange
   io.k8s.api.extensions.v1beta1.Ingress
   io.k8s.api.extensions.v1beta1.IngressBackend
   io.k8s.api.extensions.v1beta1.NetworkPolicy
   io.k8s.api.extensions.v1beta1.NetworkPolicyEgressRule
   io.k8s.api.extensions.v1beta1.NetworkPolicyIngressRule
   io.k8s.api.extensions.v1beta1.PodSecurityPolicy
   io.k8s.api.extensions.v1beta1.ReplicaSet
   io.k8s.api.extensions.v1beta1.ReplicaSetCondition
   io.k8s.api.extensions.v1beta1.RollbackConfig
   io.k8s.api.extensions.v1beta1.RunAsGroupStrategyOptions
   io.k8s.api.extensions.v1beta1.RunAsUserStrategyOptions
   io.k8s.api.extensions.v1beta1.RuntimeClassStrategyOptions
   io.k8s.api.extensions.v1beta1.SELinuxStrategyOptions
   io.k8s.api.extensions.v1beta1.SupplementalGroupsStrategyOptions
   io.k8s.apimachinery.pkg.api.resource.Quantity
   io.k8s.apimachinery.pkg.apis.meta.v1.APIGroup
   io.k8s.apimachinery.pkg.apis.meta.v1.APIResource
   io.k8s.apimachinery.pkg.apis.meta.v1.GroupVersionForDiscovery
   io.k8s.apimachinery.pkg.apis.meta.v1.LabelSelector
   io.k8s.apimachinery.pkg.apis.meta.v1.ListMeta
   io.k8s.apimachinery.pkg.apis.meta.v1.MicroTime
   io.k8s.apimachinery.pkg.apis.meta.v1.ObjectMeta
   io.k8s.apimachinery.pkg.apis.meta.v1.ServerAddressByClientCIDR
   io.k8s.apimachinery.pkg.apis.meta.v1.Time
   io.k8s.apimachinery.pkg.runtime.RawExtension
   io.k8s.apimachinery.pkg.util.intstr.IntOrString
   io.k8s.api.networking.v1beta1.HTTPIngressPath
   io.k8s.api.networking.v1beta1.Ingress
   io.k8s.api.networking.v1beta1.IngressBackend
   io.k8s.api.networking.v1.NetworkPolicy
   io.k8s.api.networking.v1.NetworkPolicyEgressRule
   io.k8s.api.networking.v1.NetworkPolicyIngressRule
   io.k8s.api.node.v1alpha1.Overhead
   io.k8s.api.node.v1alpha1.RuntimeClass
   io.k8s.api.node.v1alpha1.RuntimeClassSpec
   io.k8s.api.node.v1beta1.Overhead
   io.k8s.api.node.v1beta1.RuntimeClass
   io.k8s.api.policy.v1beta1.AllowedCSIDriver
   io.k8s.api.policy.v1beta1.AllowedFlexVolume
   io.k8s.api.policy.v1beta1.AllowedHostPath
   io.k8s.api.policy.v1beta1.FSGroupStrategyOptions
   io.k8s.api.policy.v1beta1.HostPortRange
   io.k8s.api.policy.v1beta1.IDRange
   io.k8s.api.policy.v1beta1.PodDisruptionBudget
   io.k8s.api.policy.v1beta1.PodSecurityPolicy
   io.k8s.api.policy.v1beta1.RunAsGroupStrategyOptions
   io.k8s.api.policy.v1beta1.RunAsUserStrategyOptions
   io.k8s.api.policy.v1beta1.RuntimeClassStrategyOptions
   io.k8s.api.policy.v1beta1.SELinuxStrategyOptions
   io.k8s.api.policy.v1beta1.SupplementalGroupsStrategyOptions
   io.k8s.api.rbac.v1alpha1.ClusterRole
   io.k8s.api.rbac.v1alpha1.ClusterRoleBinding
   io.k8s.api.rbac.v1alpha1.Role
   io.k8s.api.rbac.v1alpha1.RoleBinding
   io.k8s.api.rbac.v1alpha1.RoleRef
   io.k8s.api.rbac.v1alpha1.Subject
   io.k8s.api.rbac.v1beta1.ClusterRole
   io.k8s.api.rbac.v1beta1.ClusterRoleBinding
   io.k8s.api.rbac.v1beta1.Role
   io.k8s.api.rbac.v1beta1.RoleBinding
   io.k8s.api.rbac.v1beta1.RoleRef
   io.k8s.api.rbac.v1beta1.Subject
   io.k8s.api.rbac.v1.ClusterRole
   io.k8s.api.rbac.v1.ClusterRoleBinding
   io.k8s.api.rbac.v1.Role
   io.k8s.api.rbac.v1.RoleBinding
   io.k8s.api.rbac.v1.RoleRef
   io.k8s.api.rbac.v1.Subject
   io.k8s.api.scheduling.v1alpha1.PriorityClass
   io.k8s.api.scheduling.v1beta1.PriorityClass
   io.k8s.api.scheduling.v1.PriorityClass
   io.k8s.api.settings.v1alpha1.PodPreset
   io.k8s.api.storage.v1alpha1.VolumeAttachment
   io.k8s.api.storage.v1alpha1.VolumeAttachmentSource
   io.k8s.api.storage.v1alpha1.VolumeAttachmentSpec
   io.k8s.api.storage.v1alpha1.VolumeAttachmentStatus
   io.k8s.api.storage.v1alpha1.VolumeError
   io.k8s.api.storage.v1beta1.CSIDriver
   io.k8s.api.storage.v1beta1.CSIDriverSpec
   io.k8s.api.storage.v1beta1.CSINode
   io.k8s.api.storage.v1beta1.CSINodeDriver
   io.k8s.api.storage.v1beta1.CSINodeSpec
   io.k8s.api.storage.v1beta1.StorageClass
   io.k8s.api.storage.v1beta1.VolumeAttachment
   io.k8s.api.storage.v1beta1.VolumeAttachmentSource
   io.k8s.api.storage.v1beta1.VolumeAttachmentSpec
   io.k8s.api.storage.v1beta1.VolumeAttachmentStatus
   io.k8s.api.storage.v1beta1.VolumeError
   io.k8s.api.storage.v1beta1.VolumeNodeResources
   io.k8s.api.storage.v1.StorageClass
   io.k8s.api.storage.v1.VolumeAttachment
   io.k8s.api.storage.v1.VolumeAttachmentSource
   io.k8s.api.storage.v1.VolumeAttachmentSpec
   io.k8s.api.storage.v1.VolumeAttachmentStatus
   io.k8s.api.storage.v1.VolumeError
   io.k8s.kube-aggregator.pkg.apis.apiregistration.v1.APIService
   io.k8s.kube-aggregator.pkg.apis.apiregistration.v1beta1.APIService
   io.k8s.kube-aggregator.pkg.apis.apiregistration.v1beta1.ServiceReference
   io.k8s.kube-aggregator.pkg.apis.apiregistration.v1.ServiceReference
   string
  (309 rows)

  #+end_src
 
  #+BEGIN_SRC sql-mode
    select
       distinct request_uri
    from
      zraw_audit_events
    where 
      operation_id IS NULL
      AND event_verb = 'get'
      AND request_uri like '/api%'
      AND request_uri not like '%proxy%'
      AND request_uri like '%timeout%'

    order by request_uri
    LIMIT 500;
  #+END_SRC

  #+RESULTS:
  #+begin_src sql-mode
                                    request_uri                                   
  --------------------------------------------------------------------------------
   /apis/admissionregistration.k8s.io/v1beta1?timeout=32s
   /apis/apiextensions.k8s.io/v1beta1?timeout=32s
   /apis/apiregistration.k8s.io/v1beta1?timeout=32s
   /apis/apiregistration.k8s.io/v1?timeout=32s
   /apis/apps/v1beta1?timeout=32s
   /apis/apps/v1beta2?timeout=32s
   /apis/apps/v1?timeout=32s
   /apis/authentication.k8s.io/v1beta1?timeout=32s
   /apis/authentication.k8s.io/v1?timeout=32s
   /apis/authorization.k8s.io/v1beta1?timeout=32s
   /apis/authorization.k8s.io/v1?timeout=32s
   /apis/autoscaling/v1?timeout=32s
   /apis/autoscaling/v2beta1?timeout=32s
   /apis/autoscaling/v2beta2?timeout=32s
   /apis/batch/v1beta1?timeout=32s
   /apis/batch/v1?timeout=32s
   /apis/batch/v2alpha1?timeout=32s
   /apis/certificates.k8s.io/v1beta1?timeout=32s
   /apis/coordination.k8s.io/v1beta1?timeout=32s
   /apis/coordination.k8s.io/v1?timeout=32s
   /apis/crd-publish-openapi-test-common-group.k8s.io/v4?timeout=32s
   /apis/crd-publish-openapi-test-common-group.k8s.io/v5?timeout=32s
   /apis/crd-publish-openapi-test-common-group.k8s.io/v6?timeout=32s
   /apis/crd-publish-openapi-test-empty.k8s.io/v1?timeout=32s
   /apis/crd-publish-openapi-test-foo.k8s.io/v1?timeout=32s
   /apis/crd-publish-openapi-test-multi-to-single-ver.k8s.io/v5?timeout=32s
   /apis/crd-publish-openapi-test-multi-to-single-ver.k8s.io/v6alpha1?timeout=32s
   /apis/crd-publish-openapi-test-multi-ver.k8s.io/v2?timeout=32s
   /apis/crd-publish-openapi-test-multi-ver.k8s.io/v3?timeout=32s
   /apis/crd-publish-openapi-test-multi-ver.k8s.io/v4?timeout=32s
   /apis/crd-publish-openapi-test-waldo.k8s.io/v1beta1?timeout=32s
   /apis/discovery-crd-test.k8s.io/v1?timeout=32s
   /apis/events.k8s.io/v1beta1?timeout=32s
   /apis/extensions/v1beta1?timeout=32s
   /apis/kubectl-crd-test.k8s.io/v1?timeout=32s
   /apis/metrics.k8s.io/v1beta1?timeout=32s
   /apis/mygroup.example.com/v1beta1?timeout=32s
   /apis/networking.k8s.io/v1beta1?timeout=32s
   /apis/networking.k8s.io/v1?timeout=32s
   /apis/node.k8s.io/v1beta1?timeout=32s
   /apis/policy/v1beta1?timeout=32s
   /apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
   /apis/rbac.authorization.k8s.io/v1?timeout=32s
   /apis/resourcequota-crd-test.k8s.io/v1?timeout=32s
   /apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
   /apis/scheduling.k8s.io/v1alpha1?timeout=32s
   /apis/scheduling.k8s.io/v1beta1?timeout=32s
   /apis/scheduling.k8s.io/v1?timeout=32s
   /apis/settings.k8s.io/v1alpha1?timeout=32s
   /apis/snapshot.storage.k8s.io/v1alpha1?timeout=32s
   /apis/stable.example.com/v1?timeout=32s
   /apis/stable.example.com/v2?timeout=32s
   /apis/storage.k8s.io/v1beta1?timeout=32s
   /apis/storage.k8s.io/v1?timeout=32s
   /apis?timeout=32s
   /apis/wardle.k8s.io/v1alpha1?timeout=32s
   /apis/webhook-crd-test.k8s.io/v1?timeout=32s
   /apis/webhook-multiversion-crd-test.k8s.io/v1?timeout=32s
   /apis/webhook-multiversion-crd-test.k8s.io/v2?timeout=32s
   /api?timeout=32s
   /api/v1?timeout=32s
  (61 rows)

  #+end_src

** #40: PodSpec and Audit Events
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-14 Wed 23:52
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :END:
   There is only a single resource, it seems, that references podspec.  So our list of 'podspec fields' is really coming from this resource.
  
   #+RESULTS: Properties of podspec
   #+begin_src sql-mode
                field             |            name            
   -------------------------------+----------------------------
    hostIPC                       | io.k8s.api.core.v1.PodSpec
    hostPID                       | io.k8s.api.core.v1.PodSpec
    volumes                       | io.k8s.api.core.v1.PodSpec
    affinity                      | io.k8s.api.core.v1.PodSpec
    hostname                      | io.k8s.api.core.v1.PodSpec
    nodeName                      | io.k8s.api.core.v1.PodSpec
    overhead                      | io.k8s.api.core.v1.PodSpec
    priority                      | io.k8s.api.core.v1.PodSpec
    dnsConfig                     | io.k8s.api.core.v1.PodSpec
    dnsPolicy                     | io.k8s.api.core.v1.PodSpec
    subdomain                     | io.k8s.api.core.v1.PodSpec
    containers                    | io.k8s.api.core.v1.PodSpec
    hostAliases                   | io.k8s.api.core.v1.PodSpec
    hostNetwork                   | io.k8s.api.core.v1.PodSpec
    tolerations                   | io.k8s.api.core.v1.PodSpec
    nodeSelector                  | io.k8s.api.core.v1.PodSpec
    restartPolicy                 | io.k8s.api.core.v1.PodSpec
    schedulerName                 | io.k8s.api.core.v1.PodSpec
    initContainers                | io.k8s.api.core.v1.PodSpec
    readinessGates                | io.k8s.api.core.v1.PodSpec
    serviceAccount                | io.k8s.api.core.v1.PodSpec
    securityContext               | io.k8s.api.core.v1.PodSpec
    imagePullSecrets              | io.k8s.api.core.v1.PodSpec
    preemptionPolicy              | io.k8s.api.core.v1.PodSpec
    runtimeClassName              | io.k8s.api.core.v1.PodSpec
    priorityClassName             | io.k8s.api.core.v1.PodSpec
    enableServiceLinks            | io.k8s.api.core.v1.PodSpec
    serviceAccountName            | io.k8s.api.core.v1.PodSpec
    ephemeralContainers           | io.k8s.api.core.v1.PodSpec
    activeDeadlineSeconds         | io.k8s.api.core.v1.PodSpec
    shareProcessNamespace         | io.k8s.api.core.v1.PodSpec
    topologySpreadConstraints     | io.k8s.api.core.v1.PodSpec
    automountServiceAccountToken  | io.k8s.api.core.v1.PodSpec
    terminationGracePeriodSeconds | io.k8s.api.core.v1.PodSpec
   (34 rows)

   #+end_src

   #+RESULTS:
   #+begin_src sql-mode
               name            
   ----------------------------
    io.k8s.api.core.v1.PodSpec
   (1 row)
   #+end_src
  
   One thing we can try is to quickly connect the audit event to its api_operation, so that we get a standard definition of what happened.
  
   From there, we could see if that operation is part of the podSpec in some way.
 
   #+NAME: Properties of podspec
   #+BEGIN_SRC sql-mode
     SELECT 
       resource_field as field,
       api_resource_name as name
       FROM
           api_resources_fields
       WHERE api_resources_fields.api_resource_name ILIKE '%podspec%';
   #+END_SRC

   #+NAME: adding RegEx matching
   #+BEGIN_SRC sql-mode
     SELECT
       events.request_uri,
       ops.operation_id
       FROM audit_events events
          JOIN api_operations ops ON events.request_uri ~ ops.regex
       LIMIT 3;
   #+END_SRC

   #+RESULTS: adding RegEx matching
   #+begin_src sql-mode
                                       request_uri                                    |                         operation_id                          
   -----------------------------------------------------------------------------------+---------------------------------------------------------------
    /apis/rbac.authorization.k8s.io/v1beta1/namespaces/provisioning-6870/rolebindings | deleteRbacAuthorizationV1beta1CollectionNamespacedRoleBinding
    /apis/rbac.authorization.k8s.io/v1beta1/namespaces/provisioning-6870/rolebindings | listRbacAuthorizationV1beta1NamespacedRoleBinding
    /apis/rbac.authorization.k8s.io/v1beta1/namespaces/provisioning-6870/rolebindings | createRbacAuthorizationV1beta1NamespacedRoleBinding
   (3 rows)

   #+end_src

** load audit_events_via local cli
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-14 Wed 23:56
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :END:

 #+BEGIN_SRC sql-mode
   \d raw_audit_events;
   -- delete from raw_audit_events;
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
                                    Table "public.raw_audit_events"
    Column    |            Type             | Collation | Nullable |             Default              
 -------------+-----------------------------+-----------+----------+----------------------------------
  id          | integer                     |           | not null | generated by default as identity
  ingested_at | timestamp without time zone |           |          | CURRENT_TIMESTAMP
  bucket      | text                        |           |          | 
  job         | text                        |           |          | 
  data        | jsonb                       |           | not null | 
 Indexes:
     "raw_audit_events_pkey" PRIMARY KEY, btree (id)

 #+end_src


 #+NAME: load_audit_events.sh
 #+BEGIN_SRC shell :var AUDIT_LOG="../data/artifacts/ci-kubernetes-e2e-gci-gce/1134962072287711234/combined-audit.log"
   BUCKET='ci-kubernetes-e2e-gci-gce'
   JOB='1134962072287711234'
   SQL="
   CREATE TEMPORARY TABLE raw_audit_events_import (data jsonb not null) ;
   copy raw_audit_events_import (data)
   FROM STDIN (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');
   INSERT INTO raw_audit_events(data, bucket, job)
   SELECT data, '$BUCKET', '$JOB'
   FROM raw_audit_events_import;
   "
   cat $AUDIT_LOG | psql -c "$SQL"
   date
 #+END_SRC

 #+RESULTS: load_audit_events.sh
 #+begin_EXAMPLE
 INSERT 0 313431
 Thu Aug  8 01:14:52 UTC 2019
 #+end_EXAMPLE

 #+BEGIN_SRC sql-mode
   select distinct bucket, job from raw_audit_events;
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
  bucket  | job  
 ---------+------
  bucket1 | job1
 (1 row)

 #+end_src

 #+BEGIN_SRC sql-mode
 \dt+
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
                           List of relations
  Schema |       Name       | Type  | Owner |    Size    | Description 
 --------+------------------+-------+-------+------------+-------------
  public | audit_events     | table | zz    | 8192 bytes | 
  public | raw_audit_events | table | zz    | 376 MB     | 
  public | raw_swaggers     | table | zz    | 1752 kB    | 
 (3 rows)

 #+end_src

** load audit_events_via local cli
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-14 Wed 23:56
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :END:

 #+BEGIN_SRC sql-mode
   \d raw_audit_events;
   -- delete from raw_audit_events;
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
                                    Table "public.raw_audit_events"
    Column    |            Type             | Collation | Nullable |             Default              
 -------------+-----------------------------+-----------+----------+----------------------------------
  id          | integer                     |           | not null | generated by default as identity
  ingested_at | timestamp without time zone |           |          | CURRENT_TIMESTAMP
  bucket      | text                        |           |          | 
  job         | text                        |           |          | 
  data        | jsonb                       |           | not null | 
 Indexes:
     "raw_audit_events_pkey" PRIMARY KEY, btree (id)

 #+end_src


 #+NAME: load_audit_events.sh
 #+BEGIN_SRC shell :var AUDIT_LOG="../data/artifacts/ci-kubernetes-e2e-gci-gce/1134962072287711234/combined-audit.log"
   BUCKET='ci-kubernetes-e2e-gci-gce'
   JOB='1134962072287711234'
   SQL="
   CREATE TEMPORARY TABLE raw_audit_events_import (data jsonb not null) ;
   copy raw_audit_events_import (data)
   FROM STDIN (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');
   INSERT INTO raw_audit_events(data, bucket, job)
   SELECT data, '$BUCKET', '$JOB'
   FROM raw_audit_events_import;
   "
   cat $AUDIT_LOG | psql -c "$SQL"
   date
 #+END_SRC

 #+RESULTS: load_audit_events.sh
 #+begin_EXAMPLE
 INSERT 0 313431
 Thu Aug  8 01:14:52 UTC 2019
 #+end_EXAMPLE

 #+BEGIN_SRC sql-mode
   select distinct bucket, job from raw_audit_events;
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
  bucket  | job  
 ---------+------
  bucket1 | job1
 (1 row)

 #+end_src

 #+BEGIN_SRC sql-mode
 \dt+
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
                           List of relations
  Schema |       Name       | Type  | Owner |    Size    | Description 
 --------+------------------+-------+-------+------------+-------------
  public | audit_events     | table | zz    | 8192 bytes | 
  public | raw_audit_events | table | zz    | 376 MB     | 
  public | raw_swaggers     | table | zz    | 1752 kB    | 
 (3 rows)

 #+end_src

** FOOTNOTES
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-14 Wed 23:56
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :END:

** Original raw_swagger index
 #+NAME: general index the raw_swagger
 #+BEGIN_SRC sql-mode :tangle ../apps/hasura/migrations/100_table_raw_swaggers.up.sql :results silent
 CREATE INDEX idx_swagger_jsonb_ops ON raw_swaggers USING GIN (data jsonb_ops);
 CREATE INDEX idx_swagger_jsonb_path_ops ON raw_swaggers USING GIN (data jsonb_path_ops);
      -- api_operations view:
      --  , jsonb_each((raw_swaggers.data -> 'paths'::text)) paths(key, value)
      --  , jsonb_each(paths.value) d(key, value)
      --  , jsonb_array_elements((d.value -> 'tags'::text)) cat_tag(value)
      --  , jsonb_array_elements((d.value -> 'tags'::text)) jsonstring(value)
      --  , jsonb_array_elements((d.value -> 'schemes'::text)) schemestring(value)
      -- GROUP BY raw_swaggers.id, paths.key, d.key, d.value, cat_tag.value
      -- ORDER BY paths.key;
      -- api_resources view:
      --   , jsonb_each((raw_swaggers.data -> 'definitions'::text)) d(key, value)
      --   , jsonb_array_elements((d.value -> 'required'::text)) reqstring(value)
      -- GROUP BY raw_swaggers.id, d.key, d.value;
 -- CREATE INDEX idx_swagger_X ON raw_swagger USING GIN ((jsb->‘X’));
 -- CREATE INDEX idx_swagger_X ON raw_swagger USING BTREE ((jsb->>‘X’));
 -- CREATE INDEX idx_swagger_X ON raw_swagger USING HASH ((jsb->>‘X’))
 #+END_SRC
 #+NAME: api_operations indexes the raw_swagger
 #+BEGIN_SRC sql-mode :tangle ../apps/hasura/migrations/100_table_raw_swaggers.up.sql :results silent
   -- CREATE INDEX idx_swagger_gin_paths ON raw_swaggers USING GIN ((data->>'paths'));
   -- CREATE INDEX idx_swagger_btree_paths ON raw_swaggers USING BTREE ((data->>'paths'));
   -- CREATE INDEX idx_swagger_hash_paths ON raw_swaggers USING HASH ((data->>'paths'))
        -- api_operations view:
        --  , jsonb_each((raw_swaggers.data -> 'paths'::text)) paths(key, value)
        --  , jsonb_each(paths.value) d(key, value)
        --  , jsonb_array_elements((d.value -> 'tags'::text)) cat_tag(value)
        --  , jsonb_array_elements((d.value -> 'tags'::text)) jsonstring(value)
        --  , jsonb_array_elements((d.value -> 'schemes'::text)) schemestring(value)
        -- GROUP BY raw_swaggers.id, paths.key, d.key, d.value, cat_tag.value
        -- ORDER BY paths.key;
        -- api_resources view:
        --   , jsonb_each((raw_swaggers.data -> 'definitions'::text)) d(key, value)
        --   , jsonb_array_elements((d.value -> 'required'::text)) reqstring(value)
        -- GROUP BY raw_swaggers.id, d.key, d.value;
   -- CREATE INDEX idx_swagger_X ON raw_swagger USING GIN ((jsb->‘X’));
   -- CREATE INDEX idx_swagger_X ON raw_swagger USING BTREE ((jsb->>‘X’));
   -- CREATE INDEX idx_swagger_X ON raw_swagger USING HASH ((jsb->>‘X’))
   #+END_SRC
    
** load audit_events_via local cli
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 00:12
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_OLPATH: Raw Audit Events Table, and helper functions
   :ARCHIVE_CATEGORY: meta
   :END:
 #+NAME: load_audit_events.sh
 #+BEGIN_SRC shell :var AUDIT_LOG="../data/artifacts/ci-kubernetes-e2e-gci-gce/1134962072287711234/combined-audit.log"
   BUCKET='ci-kubernetes-e2e-gci-gce'
   JOB='1134962072287711234'
   SQL="
   CREATE TEMPORARY TABLE raw_audit_events_import (data jsonb not null) ;
   copy raw_audit_events_import (data)
   FROM STDIN (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');
   INSERT INTO raw_audit_events(data, bucket, job, audit_id)
   SELECT data, '$BUCKET', '$JOB'
   FROM raw_audit_events_import;
   "
   cat $AUDIT_LOG | psql -c "$SQL"
   date
 #+END_SRC

** load audit_events via plpython3u
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 00:45
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_OLPATH: Raw Audit Events Table, and helper functions
   :ARCHIVE_CATEGORY: meta
   :END:
 #+NAME: load_audit_events.py
 #+BEGIN_SRC python :tangle load_audit_events.py
   #!/usr/bin/env python3
   from urllib.request import urlopen, urlretrieve
   import os
   import re
   from bs4 import BeautifulSoup
   import subprocess
   import time
   import glob
   from tempfile import mkdtemp
   from string import Template


   def get_html(url):
       html = urlopen(url).read()
       soup = BeautifulSoup(html, 'html.parser')
       return soup


   def download_url_to_path(url, local_path):
       local_dir = os.path.dirname(local_path)
       if not os.path.isdir(local_dir):
           os.makedirs(local_dir)
       if not os.path.isfile(local_path):
           process = subprocess.Popen(['wget', '-q', url, '-O', local_path])
           downloads[local_path] = process

   # this global dict is used to track our wget subprocesses
   # wget was used because the files can get to several halfa gig
   downloads = {}
   def load_audit_events(bucket,job):
       bucket_url = f'https://storage.googleapis.com/kubernetes-jenkins/logs/{bucket}/{job}/'
       artifacts_url = f'https://gcsweb.k8s.io/gcs/kubernetes-jenkins/logs/{bucket}/{job}/artifacts'
       job_metadata_files = [
           'finished.json',
           'artifacts/metadata.json',
           'artifacts/junit_01.xml',
           'build-log.txt'
       ]
       download_path = mkdtemp( dir='/tmp', prefix=f'apisnoop-{bucket}-{job}' ) + '/'
       combined_log_file = download_path + 'audit.log'

       # meta data to download
       for jobfile in job_metadata_files:
           download_url_to_path( bucket_url + jobfile,
                                 download_path + jobfile )

       # Use soup to grab url of each of audit.log.* (some end in .gz)
       soup = get_html(artifacts_url)
       master_link = soup.find(href=re.compile("master"))
       master_soup = get_html(
           "https://gcsweb.k8s.io" + master_link['href'])
       log_links = master_soup.find_all(
           href=re.compile("audit.log"))

       # download all logs
       for link in log_links:
           log_url = link['href']
           log_file = download_path + os.path.basename(log_url)
           download_url_to_path( log_url, log_file)

       # Our Downloader uses subprocess of curl for speed
       for download in downloads.keys():
           # Sleep for 5 seconds and check for next download
           while downloads[download].poll() is None:
               time.sleep(5)
               # print("Still downloading: " + download)
           # print("Downloaded: " + download)

       # Loop through the files, (z)cat them into a combined audit.log
       with open(combined_log_file, 'ab') as log:
           for logfile in sorted(
                   glob.glob(download_path + '*kube-apiserver-audit*'), reverse=True):
               if logfile.endswith('z'):
                   subprocess.run(['zcat', logfile], stdout=log, check=True)
               else:
                   subprocess.run(['cat', logfile], stdout=log, check=True)
       # Load the resulting combined audit.log directly into raw_audit_events
       try:
           sql = Template("""CREATE TEMPORARY TABLE raw_audit_events_import (data jsonb not null) ;
           copy raw_audit_events_import (data)
           FROM PROGRAM '${cat}' (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');
           INSERT INTO raw_audit_events(data, bucket, job)
           SELECT data, '${bucket}', '${job}'
           FROM raw_audit_events_import;
           """).substitute(
               cat = f'cat {combined_log_file}',
               bucket = bucket,
               job = job
           )
           with open(download_path + 'load.sql', 'w') as sqlfile:
             sqlfile.write(sql)
           rv = plpy.execute(sql)
           return "it worked"
       except plpy.SPIError:
           return "something went wrong with plpy"
       except:
           return "something unknown went wrong"
   if __name__ == "__main__":
       load_audit_events('ci-kubernetes-e2e-gci-gce','1134962072287711234')
   else:
       load_audit_events(bucket,job)
 #+END_SRC

 #+NAME: min_load_audit_events.py
 #+BEGIN_SRC python :tangle min_load_audit_events.py
   return f'{bucket} + {job}'
   # from urllib.request import urlopen, urlretrieve
   # import os
   # import re
   # from bs4 import BeautifulSoup
   # import subprocess
   # import time
   # import glob
   # from tempfile import mkdtemp
   # from string import Template
   # return "WERAN"
 #+END_SRC

 #+NAME: load_audit_events.sql
 #+BEGIN_SRC sql-mode :noweb yes :notangle ../apps/hasura/migrations/245_function_load_audit_events.up.sql :results silent
   set role dba;
   CREATE OR REPLACE FUNCTION load_audit_events(bucket text, job text)
   RETURNS text AS $$
   <<load_audit_events.py>>
   $$ LANGUAGE plpython3u ;
   reset role;
 #+END_SRC

 #+NAME: reload sample audit event
 #+BEGIN_SRC sql-mode :noweb yes :notangle ../apps/hasura/migrations/250_populate_audit_events.up.sql
   select * from load_audit_events('ci-kubernetes-e2e-gci-gce','1134962072287711234');
   -- select * from load_swagger_via_curl('release-1.15');
   -- select * from load_swagger_via_curl('release-1.14');
   -- select * from load_swagger_via_curl('release-1.13');
   -- select * from load_swagger_via_curl('release-1.12');
   -- select * from load_swagger_via_curl('release-1.11');
   -- select * from load_swagger_via_curl('release-1.10');
 #+END_SRC

 #+NAME: min_load_audit_events.py
 #+BEGIN_SRC python :tangle min_load_audit_events.py
   return f'{bucket} + {job}'
   # from urllib.request import urlopen, urlretrieve
   # import os
   # import re
   # from bs4 import BeautifulSoup
   # import subprocess
   # import time
   # import glob
   # from tempfile import mkdtemp
   # from string import Template
   # return "WERAN"
 #+END_SRC

** responseObjects
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 00:48
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_OLPATH: Raw Audit Events Table, and helper functions/Audit Events View
   :ARCHIVE_CATEGORY: meta
   :END:
*** columns
**** responsekind
 #+NAME: responseObject.kind
 #+BEGIN_SRC sql-mode
     responsekind text NOT NULL,
 #+END_SRC

***** Examples
 #+BEGIN_SRC json
 "responseObject": {
     "kind": "SubjectAccessReview",
 #+END_SRC

 #+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq  -r .responseObject.kind | sort | uniq > kinds.txt
 cat kube-apiserver-audit.log | jq  -r .responseObject.kind | sort | uniq > rkinds.txt
 diff kinds.txt rkinds.txt
 #+END_SRC

 Only responseObjects include Binding, DeleteOptions, and DeploymentRollback
 Only responsesObjects include Status and TokenResponse

 #+BEGIN_SRC diff
 2d1
 < Binding
 12d10
 < DeleteOptions
 14d11
 < DeploymentRollback
 39a37
 > Status
 41a40
 > TokenResponse
 #+END_SRC

**** responseapiversion
 #+NAME: responseObject.apiVersion
 #+BEGIN_SRC sql-mode
   responseapiversion text NOT NULL,
 #+END_SRC
 Might be tied to level = response, response etc
***** examples
 #+BEGIN_SRC json
 "responseObject": {
     "apiVersion": "authorization.k8s.io/v1",
 #+END_SRC

 I'm not sure here, but I feel like we should only be looking at ResponseResponse... not all three.
 Huh, that was wrong.. the counts differ wildly:

**** responsemeta
 #+NAME: responseObject.metadata
 #+BEGIN_SRC sql-mode
   responsemeta jsonb NOT NULL,
 #+END_SRC
***** examples
 #+BEGIN_SRC json
 "responseObject": {
     "metadata": {
       "creationTimestamp": null
     },
 #+END_SRC
**** responsespec
 #+NAME: responseObject.spec
 #+BEGIN_SRC sql-mode
   responsespec jsonb NOT NULL,
 #+END_SRC
***** examples
 #+BEGIN_SRC json
 "responseObject": {
     "spec": {
       "resourceAttributes": {
         "namespace": "kubernetes-dashboard-6069",
         "verb": "use",
         "group": "extensions",
         "resource": "podsecuritypolicies",
         "name": "e2e-test-privileged-psp"
       },
       "user": "system:serviceaccount:kubernetes-dashboard-6069:default"
     },
 #+END_SRC
**** responsestatus
 #+NAME: responseObject.status
 #+BEGIN_SRC sql-mode
   responsestatus jsonb NOT NULL,
 #+END_SRC
***** examples
 #+BEGIN_SRC json
   "responseObject": {
     "status": {
       "allowed": true,
       "reason": "RBAC: allowed by RoleBinding \"kubernetes-dashboard-6069--e2e-test-privileged-psp/kubernetes-dashboard-6069\" of ClusterRole \"e2e-test-privileged-psp\" to ServiceAccount \"default/kubernetes-dashboard-6069\""
     }
 #+END_SRC

*** Notes
 #+BEGIN_SRC json
   "responseObject": {
     "kind": "SubjectAccessReview",
     "apiVersion": "authorization.k8s.io/v1",
     "metadata": {
       "creationTimestamp": null
     },
     "spec": {
       "resourceAttributes": {
         "namespace": "kubernetes-dashboard-6069",
         "verb": "use",
         "group": "extensions",
         "resource": "podsecuritypolicies",
         "name": "e2e-test-privileged-psp"
       },
       "user": "system:serviceaccount:kubernetes-dashboard-6069:default"
     },
     "status": {
       "allowed": true,
       "reason": "RBAC: allowed by RoleBinding \"kubernetes-dashboard-6069--e2e-test-privileged-psp/kubernetes-dashboard-6069\" of ClusterRole \"e2e-test-privileged-psp\" to ServiceAccount \"default/kubernetes-dashboard-6069\""
     }
   },
 #+END_SRC

** TODO Create Import for CSV view
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 00:48
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :ARCHIVE_TODO: TODO
   :END:
   We have a file started here: [[file:test_gen.org][test_gen.org]] 
   that brings in the work devan and caleb did to pull all the tests used in a specific/commit version of k8s.
   If we can build a script for this, then we can have:
   - A test name
   - its description
   - its link to official k8s definition
   - a link to the lines of go code that define it.
  
     We can then use this as a cross refernece for any audit event that references a test.

    
*** load audit_events_via local cli

 #+NAME: load_audit_events.sh
 #+BEGIN_SRC shell :var AUDIT_LOG="../data/artifacts/ci-kubernetes-e2e-gci-gce/1134962072287711234/combined-audit.log"
   BUCKET='ci-kubernetes-e2e-gci-gce'
   JOB='1134962072287711234'
   SQL="
   CREATE TEMPORARY TABLE raw_audit_events_import (data jsonb not null) ;
   copy raw_audit_events_import (data)
   FROM STDIN (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');
   INSERT INTO raw_audit_events(data, bucket, job)
   SELECT data, '$BUCKET', '$JOB'
   FROM raw_audit_events_import;
   "
   cat $AUDIT_LOG | psql -c "$SQL"
   date
 #+END_SRC

**** requestObjects
***** columns
****** requestkind
   #+NAME: requestObject.kind
   #+BEGIN_SRC sql-mode
       requestkind text NOT NULL,
   #+END_SRC

******* Examples
   #+BEGIN_SRC json
   "requestObject": {
       "kind": "SubjectAccessReview",
   #+END_SRC

   #+BEGIN_SRC shell
   cat kube-apiserver-audit.log | jq  -r .requestObject.kind | sort | uniq > kinds.txt
   cat kube-apiserver-audit.log | jq  -r .responseObject.kind | sort | uniq > rkinds.txt
   diff kinds.txt rkinds.txt
   #+END_SRC

   Only requestObjects include Binding, DeleteOptions, and DeploymentRollback
   Only responsesObjects include Status and TokenRequest

   #+BEGIN_SRC diff
   2d1
   < Binding
   12d10
   < DeleteOptions
   14d11
   < DeploymentRollback
   39a37
   > Status
   41a40
   > TokenRequest
   #+END_SRC

****** requestapiversion
   #+NAME: requestObject.apiVersion
   #+BEGIN_SRC sql-mode
     requestapiversion text NOT NULL,
   #+END_SRC
   Might be tied to level = request, response etc
******* examples
   #+BEGIN_SRC json
   "requestObject": {
       "apiVersion": "authorization.k8s.io/v1",
   #+END_SRC

   I'm not sure here, but I feel like we should only be looking at RequestResponse... not all three.
   Huh, that was wrong.. the counts differ wildly:

****** requestmeta
   #+NAME: requestObject.metadata
   #+BEGIN_SRC sql-mode
     requestmeta jsonb NOT NULL,
   #+END_SRC
******* examples
   #+BEGIN_SRC json
   "requestObject": {
       "metadata": {
         "creationTimestamp": null
       },
   #+END_SRC
****** requestspec
   #+NAME: requestObject.spec
   #+BEGIN_SRC sql-mode
     requestspec jsonb NOT NULL,
   #+END_SRC
******* examples
   #+BEGIN_SRC json
   "requestObject": {
       "spec": {
         "resourceAttributes": {
           "namespace": "kubernetes-dashboard-6069",
           "verb": "use",
           "group": "extensions",
           "resource": "podsecuritypolicies",
           "name": "e2e-test-privileged-psp"
         },
         "user": "system:serviceaccount:kubernetes-dashboard-6069:default"
       },
   #+END_SRC
****** requeststatus
   #+NAME: requestObject.status
   #+BEGIN_SRC sql-mode
     requeststatus jsonb NOT NULL,
   #+END_SRC
******* examples
   #+BEGIN_SRC json
     "responseObject": {
       "status": {
         "allowed": true,
         "reason": "RBAC: allowed by RoleBinding \"kubernetes-dashboard-6069--e2e-test-privileged-psp/kubernetes-dashboard-6069\" of ClusterRole \"e2e-test-privileged-psp\" to ServiceAccount \"default/kubernetes-dashboard-6069\""
       }
   #+END_SRC

***** table

   We'll just load these as jsonb into the main audit_events table.

   From https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.15/

   #+BEGIN_EXAMPLE
   Resource objects typically have 3 components:

   Resource ObjectMeta: This is metadata about the resource, such as its name, type, api version, annotations, and labels. This contains fields that maybe updated both by the end user and the system (e.g. annotations).

   ResourceSpec: This is defined by the user and describes the desired state of system. Fill this in when creating or updating an object.

   ResourceStatus: This is filled in by the server and reports the current state of the system. In most cases, users don't need to change this.
   #+END_EXAMPLE

   These have more information
   #+BEGIN_SRC json
   "requestObject": {
       "kind": "SubjectAccessReview",
       "apiVersion": "authorization.k8s.io/v1",
       "metadata": {
         "creationTimestamp": null
       },
       "spec": {
         "resourceAttributes": {
           "namespace": "kubernetes-dashboard-6069",
           "verb": "use",
           "group": "extensions",
           "resource": "podsecuritypolicies",
           "name": "e2e-test-privileged-psp"
         },
         "user": "system:serviceaccount:kubernetes-dashboard-6069:default"
       },
       "status": {
         "allowed": false
       }
     },
   #+END_SRC

** FOOTNOTES
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 00:57
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :END:

** event_verb_to_http_method
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 14:19
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_OLPATH: FOOTNOTES
   :ARCHIVE_CATEGORY: meta
   :END:

 #+BEGIN_SRC sql-mode :notangle ../apps/hasura/migrations/222_function_verb_to_method.up.sql :results silent
   CREATE FUNCTION event_verb_to_http_method(verb text) RETURNS text as $$
   BEGIN
     CASE
     WHEN verb = 'get' OR
          verb = 'list' OR
          verb = 'proxy'
     THEN return 'get' ;

     WHEN verb = 'deletecollection' OR
          verb = 'delete'
     THEN return 'delete' ;

     WHEN verb = 'watch' OR
          verb = 'watchlist'
     THEN return 'watch' ;

     WHEN verb = 'create'
     THEN return 'post' ;

     WHEN verb = 'update'
     THEN return 'put' ;

     WHEN verb = 'patch'
     THEN return 'patch' ;

     ELSE return null ;
     END CASE;
   END;
   $$ LANGUAGE plpgsql;
 #+END_SRC

 #+BEGIN_SRC sql-mode
 select * from event_verb_to_http_method('proxy');
 -- select * from event_verb_to_http_method('deletecollection');
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
  event_verb_to_http_method 
 ---------------------------
  get
 (1 row)

 #+end_src

** Working with this repo/org file
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 14:21
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_CATEGORY: meta
   :END:
*** Work happens in Org first
    Within ii, our emphasis is on the documentation/org-file first.  
    We can document and craft the queries for our db, then tangle them into our migration files.
    as such: 
    *NOTE: Don't commit the hasura/migrations, they should be tangled from the org file.*
    In the future, we may add a commit hook that tangles org => hasura

** config.yaml
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 14:21
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_OLPATH: Hasura
   :ARCHIVE_CATEGORY: meta
   :END:

 Can be used by itself to run hasura cli or console from another host

 #+NAME: hasura config.yaml
 #+BEGIN_SRC yaml :tangle ../apps/hasura/config.yaml
 endpoint: http://sharing.io:8888
 #+END_SRC

** Watch hasura logs
   :PROPERTIES:
   :ARCHIVE_TIME: 2019-08-15 Thu 14:21
   :ARCHIVE_FILE: ~/ii/apisnoop_v3/org/meta.org
   :ARCHIVE_OLPATH: Hasura
   :ARCHIVE_CATEGORY: meta
   :END:
 #+NAME: Watch Hasura Logs
 #+BEGIN_SRC emacs-lisp
     (defun hasura-logs ()
       (interactive)
       (setq *hasura-buffer*
             (get-buffer-create "hasura-logs"))
       (with-current-buffer *hasura-buffer*
         (ansi-color-for-comint-mode-on)
         (comint-mode)
         (spacemacs/toggle-line-numbers-on)
        ;; (linum-mode t)
         )
       (let ((default-directory (file-name-directory (concat (file-name-directory buffer-file-name) "../apps/hasura/")))
             (logs-command "docker-compose logs -f --no-color")
             ;; (logs-command "tail -f /var/log/messages")
             ;;(logs-command "docker-compose logs -f --no-color 2>/dev/null | sed 's:hasura_1  | ::g' | grep '^{' | jq .")
             )
         (setq *hasura-process*
               (start-file-process-shell-command
                "hasura" *hasura-buffer* logs-command))
         (set-process-filter *hasura-process* 'comint-output-filter)
   )
       )
     (hasura-logs)
     ;; unsure how to display
     ;; (add-to-list 'display-buffer-alist
     ;;            '("hasura-logs" . ((display-buffer-pop-up-window) .
     ;;                               ((inhibit-same-window . t)))))
     ;; (
     ;; display-buffer (get-buffer "hasura-logs") nil)
     ;; "docker-compose logs -f| jq .")
 #+END_SRC

 #+RESULTS:
 #+begin_src emacs-lisp
 comint-output-filter
 #+end_src

