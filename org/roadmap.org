# -*- ii: mode; -*-
#+TODO: ORG(o) MOCK(m) TRIAGE(r) BACKLOG(b) TEST(t) PROMOTION(p) FLAKING(f) COMMENTS(c) | DONE(d)
#+TITLE: APISnoop OKRs

* 2020 Q1
** Increase Stable Test Coverage Velocity 100% over 2019
*** KR1 (26/+27) new conformant stable endpoints
**** Done = 5
***** DONE +3 Promote: Secret patching test #87262
      CLOSED: [2020-04-02 Thu 06:49]
***** DONE +1 Promote: find Kubernetes Service in default Namespace #87260
      CLOSED: [2020-04-02 Thu 06:50]
***** DONE +1 Promote: Namespace patch test #87256
      CLOSED: [2020-04-02 Thu 06:50]
**** Needs Approval +3
***** PROMOTION +3 Promote: pod PreemptionExecutionPath verification
Messaged belamaric
  ? #issue
  ? #test 
  https://github.com/kubernetes/kubernetes/pull/83378 # promotion
**** Needs Review +9
***** TEST +3 Promote: PodTemplate Lifecycle test #88036 (possibly flakes)
  https://github.com/kubernetes/kubernetes/issues/86141 #issue
  Needs reopening and checkboxes for current state..
  https://github.com/kubernetes/kubernetes/pull/88036#ref-pullrequest-571656281 # promotion
  https://github.com/kubernetes/kubernetes/pull/88588#issuecomment-606957802 # related flaking comments
***** COMMENTS +2 Promote: ConfigMap Lifecycle test #88034 (needs addressing)
  https://github.com/kubernetes/kubernetes/pull/88034#discussion_r398728147
 https://github.com/kubernetes/kubernetes/pull/89707 PR to possibly handle timeouts
 Find an example
***** COMMENTS +4 Pod and PodStatus
  https://github.com/kubernetes/kubernetes/issues/88545 #issue / mock-test
  https://github.com/kubernetes/kubernetes/pull/89453 #test
  https://github.com/kubernetes/kubernetes/pull/89453#discussion_r400346746
  Not sure this will work, you will be racing with the kubelet, I think. That is, kubelet may mark it ready again.
**** In Progress +18
***** TEST +4 Promote: Endpoints
  https://github.com/kubernetes/kubernetes/issues/87762 #issue
  https://github.com/kubernetes/kubernetes/pull/88778 # test
  https://github.com/kubernetes/kubernetes/pull/89752 # promotion

  [[https://testgrid.k8s.io/sig-release-master-blocking#gce-cos-master-default&include-filter-by-regex=should%2520test%2520the%2520lifecycle%2520of%2520an%2520Endpoint][TestGrid reference]] 

***** TEST +5 Promote: Event Lifecycle test #86858
  https://github.com/kubernetes/kubernetes/issues/86288 #issue
  https://github.com/kubernetes/kubernetes/pull/86858 #test
  https://github.com/kubernetes/kubernetes/pull/89753 # promotion
  
  [[https://testgrid.k8s.io/sig-release-master-blocking#gce-cos-master-default&include-filter-by-regex=should%2520ensure%2520that%2520an%2520event%2520can%2520be%2520fetched%252C%2520patched%252C%2520deleted%252C%2520and%2520listed][TestGrid reference]] 
  
***** FLAKING +7 ReplicationController lifecycle
  https://github.com/kubernetes/kubernetes/issues/88302 #issue / mock test
  Needs reopening and checkboxes for current state...
  https://github.com/kubernetes/kubernetes/pull/88588 # test is flaking
**** Sorted Backlog +5
***** BACKLOG +2 ServiceStatus lifecycle
 https://github.com/cncf/apisnoop/pull/298 # apisnoop needs link to ticket?
 https://github.com/kubernetes/kubernetes/issues/89135 # new issue?
 Currently, this test is having issues writing to the ServiceStatus endpoints (via patch and update).
 The data is patched without errors, but the data when fetched is no different to before the patching.
***** BACKLOG +3 ServiceAccount lifecycle
 https://github.com/kubernetes/kubernetes/issues/89071 # issue
 @johnbelamaric You don't need to check the status of the secret as part of the test. In other places we check that the resource in question happens, we don't have to follow.
**** Triage +12
***** TRIAGE +5 Apps DaemonSet lifecycle
 https://github.com/cncf/apisnoop/pull/305 # apisnoop
 https://github.com/kubernetes/kubernetes/issues/89637 # issue
***** TRIAGE +5 Apps Deployment lifecycle
 ? # apisnoop
 https://github.com/kubernetes/kubernetes/issues/89340 # issue
***** TRIAGE +2 NodeStatus                                    :deprioritized:
      Needs these comments addressed
  https://github.com/kubernetes/kubernetes/issues/88358#issuecomment-591062171
 
*** KR2 +6% Coverage Increase
 Should be displayed on apisnoop.cncf.io
** Complete cncf/apisnoop prow.k8s.io + EKS migration
*** KR1 All cncf/apisnoop artifacts created by prow.k8s.io
*** KR2 All cncf/apisnoop github workflow managed by prow.k8s.io
*** KR3 All cncf/apisnoop non-prow infra moved to EKS
** Mentor/Teach test-writing workflow at Contributer Summit / KubeConEU
*** KR1 Caleb and Hippie Mentoring at Contributor Summit
I am pairing weekly with Guin and Mallian to ensure the workflow is accessible.
*** KR2 Riaan teaching test writing
* 2020 Q2
** Increase Stable Test Coverage Velocity 50% over Q1
*** KR1 (0/+40) new conformant stable endpoints
*** KR2 +9% Coverage Increase
*** KR3 (stretch) 50% stable endpoints hit by conformance tests
** Prepare to Gate k/k PRs touching test/e2e or API
*** KR1 comment w/ list of increase/decrease of stable endpoints
*** KR2 gate w/ comment
** Prepare to Gate cncf/k8s-conformance PRs touching v*.*/
*** KR1 comment w/ list of unrun conformance tests
*** KR2 gate w/ comment
