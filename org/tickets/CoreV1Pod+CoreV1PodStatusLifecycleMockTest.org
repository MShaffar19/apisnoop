# -*- ii: apisnoop; -*-
#+TITLE: Mock Ticket Template
#+AUTHOR: ii team
#+TODO: TODO(t) NEXT(n) IN-PROGRESS(i) BLOCKED(b) | DONE(d)
#+OPTIONS: toc:nil tags:nil todo:nil
#+EXPORT_SELECT_TAGS: export
* TODO [0%] In-Cluster Setup                                    :neverexport:
  :PROPERTIES:
  :LOGGING:  nil
  :END:
** TODO Connect demo to right eye

   #+begin_src tmate :session foo:hello :eval never-export
     echo "What parts of Kubernetes do you depend on $USER?"
   #+end_src
** Tilt Up
   #+begin_src tmate :session foo:hello :eval never-export
     cd ~/apisnoop
     tilt up --host 0.0.0.0
   #+end_src
** TODO Verify Pods Running
   #+begin_src shell
     kubectl get pods
   #+end_src

   #+RESULTS:
   #+begin_example
   NAME                                    READY   STATUS    RESTARTS   AGE
   apisnoop-auditlogger-86dcf97749-nb2rp   1/1     Running   1          6d23h
   hasura-7c5775fc95-rmp28                 1/1     Running   1          6d23h
   kubemacs-0                              1/1     Running   1          6d23h
   pgadmin-78b7448594-bmvxl                1/1     Running   0          6d23h
   postgres-6dbf95b969-hpr7k               1/1     Running   0          6d23h
   webapp-5bd67b658b-fc6pr                 1/1     Running   0          6d23h
   #+end_example

** TODO Check it all worked

   #+begin_src sql-mode :results replace
     \d+
   #+end_src

   #+RESULTS:
   #+begin_SRC example
                                                                              List of relations
    Schema |               Name               |       Type        |  Owner   |  Size   |                                    Description                                    
   --------+----------------------------------+-------------------+----------+---------+-----------------------------------------------------------------------------------
    public | api_operation                    | view              | apisnoop | 0 bytes | 
    public | api_operation_material           | materialized view | apisnoop | 3056 kB | details on each operation_id as taken from the openAPI spec
    public | api_operation_parameter_material | materialized view | apisnoop | 5008 kB | the parameters for each operation_id in open API spec
    public | audit_event                      | view              | apisnoop | 0 bytes | a record for each audit event in an audit log
    public | bucket_job_swagger               | table             | apisnoop | 3128 kB | metadata for audit events  and their respective swagger.json
    public | endpoint_coverage                | view              | apisnoop | 0 bytes | the test hits and conformance test hits per operation_id & other useful details
    public | endpoint_coverage_material       | materialized view | apisnoop | 144 kB  | 
    public | endpoints_hit_by_new_test        | view              | apisnoop | 0 bytes | list endpoints hit during our live auditing alongside their current test coverage
    public | projected_change_in_coverage     | view              | apisnoop | 0 bytes | overview of coverage stats if the e2e suite included your tests
    public | raw_audit_event                  | table             | apisnoop | 4405 MB | a record for each audit event in an audit log
    public | stable_endpoint_stats            | view              | apisnoop | 0 bytes | coverage stats for entire test run, looking only at its stable endpoints
    public | tests                            | view              | apisnoop | 0 bytes | 
    public | untested_stable_core_endpoints   | view              | apisnoop | 0 bytes | list stable core endpoints not hit by any tests, according to their test run
    public | useragents                       | view              | apisnoop | 0 bytes | 
   (14 rows)

   #+end_SRC

** TODO Check current coverage
   #+NAME: stable endpoint stats
   #+begin_src sql-mode
     select * from stable_endpoint_stats where job != 'live';
   #+end_src

   #+RESULTS: stable endpoint stats
   #+begin_SRC example
            job         |    date    | total_endpoints | test_hits | conf_hits | percent_tested | percent_conf_tested 
   ---------------------+------------+-----------------+-----------+-----------+----------------+---------------------
    1229108788603129860 | 2020-02-16 |             438 |       190 |       138 |          43.38 |               31.51
   (1 row)

   #+end_SRC

* Identify an untested feature Using APISnoop                        :export:

According to this APIsnoop query, there are still some remaining Pod endpoints which are untested.

  #+NAME: untested_stable_core_endpoints
  #+begin_src sql-mode :eval never-export :exports both :session none
    SELECT
      operation_id,
      -- k8s_action,
      -- path,
      -- description,
      kind
      FROM untested_stable_core_endpoints
      where path not like '%volume%'
      and kind like 'Pod'
      -- and kind like ''
      -- and operation_id ilike '%%'
     ORDER BY kind,operation_id desc
     -- LIMIT 25
           ;
  #+end_src

 #+RESULTS: untested_stable_core_endpoints
 #+begin_SRC example
             operation_id             | kind 
 -------------------------------------+------
  replaceCoreV1NamespacedPodStatus    | Pod
  readCoreV1NamespacedPodStatus       | Pod
  listCoreV1PodForAllNamespaces       | Pod
  deleteCoreV1CollectionNamespacedPod | Pod
 (4 rows)

 #+end_SRC

* Use API Reference to Lightly Document the Feature                  :export:
- [[https://kubernetes.io/docs/reference/kubernetes-api/][Kubernetes API Reference Docs]]
- [client-go - Pod](https://github.com/kubernetes/client-go/blob/master/kubernetes/typed/core/v1/pod.go)

* The mock test                                                      :export:
** Test outline
1. Create a Pod with a static label

2. Patch the Pod with a new Label and updated data

3. Get the Pod to ensure it's patched

4. Read the Pod's status

5. Replace the Pod's status Ready condition to False

6. Read the Pod's status to check if Ready is False

7. List all Pods in all Namespaces
   find the Pod(1)
   ensure that the Pod is found and is patched

8. Delete Namespaced Pod(1) via a Collection with a LabelSelector

9. Get the Pod to check that it's deleted

** Example in Go
   #+begin_src go
     package main

     import (
       "encoding/json"
       "time"
       "fmt"
       "flag"
       "os"

       v1 "k8s.io/api/core/v1"
       "k8s.io/client-go/dynamic"
       "k8s.io/apimachinery/pkg/runtime/schema"
       metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
       "k8s.io/client-go/kubernetes"
       "k8s.io/apimachinery/pkg/types"
       "k8s.io/client-go/tools/clientcmd"
     )

     func main() {
       // uses the current context in kubeconfig
       kubeconfig := flag.String("kubeconfig", fmt.Sprintf("%v/%v/%v", os.Getenv("HOME"), ".kube", "config"), "(optional) absolute path to the kubeconfig file")
       flag.Parse()
       config, err := clientcmd.BuildConfigFromFlags("", *kubeconfig)
       if err != nil {
           fmt.Println(err)
           return
       }
       // make our work easier to find in the audit_event queries
       config.UserAgent = "live-test-writing"
       // creates the clientset
       ClientSet, _ := kubernetes.NewForConfig(config)
       DynamicClientSet, _ := dynamic.NewForConfig(config)
       podResource := schema.GroupVersionResource{Group: "", Version: "v1", Resource: "pods"}

       testNs := "default"
       testPodName := "pod-test"
       testPodImage := "nginx"
       testPodImage2 := "nginx"

       testPod := v1.Pod{
           ObjectMeta: metav1.ObjectMeta{
               Name: testPodName,
               Labels: map[string]string{
                   "test-pod-static": "true",
               },
           },
           Spec: v1.PodSpec{
               Containers: []v1.Container{
                   {
                      Name: testPodName,
                      Image: testPodImage,
                   },
               },
           },
       }
       // create Pod with a static label
       _, err = ClientSet.CoreV1().Pods(testNs).Create(&testPod)
       if err != nil {
           fmt.Println(err)
           return
       }
       fmt.Println("[status] created Pod")

       // setup a watch for the RC
       podWatch, err := ClientSet.CoreV1().Pods(testNs).Watch(metav1.ListOptions{LabelSelector: "test-pod-static=true"})
       if err != nil {
           fmt.Println(err)
           return
       }
       podWatchChan := podWatch.ResultChan()

       fmt.Println("[status] watching for Pod to be ready")
       for event := range podWatchChan {
           podEvent, ok := event.Object.(*v1.Pod)
           if ok != true {
              fmt.Println("Unable to fix type")
              return
           }
           if podEvent.Status.Phase == "Running" {
              break
           }
       }
       fmt.Println("[status] Pod is Ready")

       // patch the Pod with a new Label and updated data
       podPatch, err := json.Marshal(map[string]interface{}{
           "metadata": map[string]interface{}{
               "labels": map[string]string{
                   "podtemplate": "patched",
               },
           },
           "spec": map[string]interface{}{
               "containers": []map[string]interface{}{
                   {
                       "name": testPodName,
                       "image": testPodImage2,
                   },
               },
           },
       })
       if err != nil {
           fmt.Println(err)
           return
       }
       _, err = ClientSet.CoreV1().Pods(testNs).Patch(testPodName, types.StrategicMergePatchType, []byte(podPatch))
       if err != nil {
           fmt.Println(err)
           return
       }

       // get the Pod and ensure it's patched
       pod, err := ClientSet.CoreV1().Pods(testNs).Get(testPodName, metav1.GetOptions{})
       if err != nil {
           fmt.Println(err)
           return
       }
       if pod.ObjectMeta.Labels["test-pod-static"] != "true" || pod.Spec.Containers[0].Image != testPodImage2 {
           fmt.Println("[error] patching of Pod failed")
           return
       }

       // get pod status
       podStatusUnstructured, err := DynamicClientSet.Resource(podResource).Namespace(testNs).Get(testPodName, metav1.GetOptions{}, "status")
       if err != nil {
           fmt.Println(err)
           return
       }
       podStatusUjson, _ := json.Marshal(podStatusUnstructured)
       var podStatus v1.Pod
       json.Unmarshal(podStatusUjson, &podStatus)

       // replace the Pod's status Ready condition to False
       podStatusUpdated := podStatus
       podStatusFieldPatchCount := 0
       podStatusFieldPatchCountTotal := 2
       for pos, cond := range podStatusUpdated.Status.Conditions {
           if (cond.Type == "Ready" && cond.Status == "True") || (cond.Type == "ContainersReady" && cond.Status == "True") {
               podStatusUpdated.Status.Conditions[pos].Status = "False"
               podStatusFieldPatchCount++
           }
       }
       if podStatusFieldPatchCount != podStatusFieldPatchCountTotal {
           fmt.Println("[error] failed to patch all relevant Pod conditions")
           return
       }
       _, err = ClientSet.CoreV1().Pods(testNs).UpdateStatus(&podStatusUpdated)
       if err != nil {
           fmt.Println(err)
           return
       }
       fmt.Println("[status] updated PodStatus")

       // list all Pods and get their status to ensure it's Ready condition is False
       podsList, err := ClientSet.CoreV1().Pods("").List(metav1.ListOptions{LabelSelector: "test-pod-static=true"})
       if err != nil {
           fmt.Println(err)
           return
       }
       fmt.Println("[status] fetched all Pods by LabelSelector")
       podStatusFieldPatchCount = 0
       podStatusFieldPatchCountTotal = 2
       for _, podItem := range podsList.Items {
           for _, cond := range podItem.Status.Conditions {
               if (cond.Type == "Ready" && cond.Status == "False") || (cond.Type == "ContainersReady" && cond.Status == "False") {
                   podStatusFieldPatchCount++
               }
           }
       }
       if podStatusFieldPatchCount != podStatusFieldPatchCountTotal {
           fmt.Printf("[error] failed to update PodStatus - %v/%v conditions failed to update (%v, %v)", podStatusFieldPatchCount, podStatusFieldPatchCountTotal, "Ready", "ContainersReady")
           return
       }
       fmt.Println("[status] PodStatus was updated successful")

       // delete the Pod via a Collection with a LabelSelector
       err = ClientSet.CoreV1().Pods(testNs).DeleteCollection(&metav1.DeleteOptions{}, metav1.ListOptions{LabelSelector: "test-pod-static=true"})
       if err != nil {
           fmt.Println(err)
           return
       }

       fmt.Println("[status] watching for Pod to be not Ready")
       podEventChannel:
       for event := range podWatchChan {
           podEvent, ok := event.Object.(*v1.Pod)
           if ok != true {
               fmt.Println("Unable to fix type")
               return
           }

           podStatusFieldPatchCount := 0
           podStatusFieldPatchCountTotal := 2
           for _, cond := range podEvent.Status.Conditions {
               if (cond.Type == "Ready" && cond.Status == "False") || (cond.Type == "ContainersReady" && cond.Status == "False") {
                   podStatusFieldPatchCount++
               }
           }
           if podStatusFieldPatchCount == podStatusFieldPatchCountTotal {
               break podEventChannel
           }
       }
       time.Sleep(5 * time.Second)

       fmt.Println("[status] Pod no longer available")

       // fetch the Pod to check if it's deleted
       _, err = ClientSet.CoreV1().Pods(testNs).Get(testPodName, metav1.GetOptions{})
       if err == nil {
           fmt.Println("[error] Pod still available after deletion; failed to delete Pod")
           return
       }

       // write test here
       fmt.Println("[status] complete")

     }
   #+end_src

   #+RESULTS:
   #+begin_src go
   [status] created Pod
   [status] watching for Pod to be ready
   [status] Pod is Ready
   [status] updated PodStatus
   [status] fetched all Pods by LabelSelector
   [status] PodStatus was updated successful
   [status] watching for Pod to be not Ready
   [status] Pod no longer available
   [status] complete
   #+end_src

* Verify Increase it Coverage with APISnoop                          :export:
Discover useragents:
  #+begin_src sql-mode :eval never-export :exports both :session none
    select distinct useragent from audit_event where bucket='apisnoop' and useragent not like 'kube%' and useragent not like 'coredns%' and useragent not like 'kindnetd%' and useragent like 'live%';
  #+end_src

  #+RESULTS:
  #+begin_SRC example
       useragent     
  -------------------
   live-test-writing
  (1 row)

  #+end_SRC

List endpoints hit by the test:
#+begin_src sql-mode :exports both :session none
select * from endpoints_hit_by_new_test where useragent like 'live%'; 
#+end_src

#+RESULTS:
#+begin_SRC example
     useragent     |            operation_id             | hit_by_ete | hit_by_new_test 
-------------------+-------------------------------------+------------+-----------------
 live-test-writing | readCoreV1NamespacedPodStatus       | f          |               1
 live-test-writing | readCoreV1NamespacedPod             | t          |               2
 live-test-writing | deleteCoreV1CollectionNamespacedPod | f          |               2
 live-test-writing | patchCoreV1NamespacedPod            | t          |               2
 live-test-writing | listCoreV1PodForAllNamespaces       | f          |               1
 live-test-writing | createCoreV1NamespacedPod           | t          |               2
 live-test-writing | replaceCoreV1NamespacedPodStatus    | f          |               2
 live-test-writing | listCoreV1NamespacedPod             | t          |               1
(8 rows)

#+end_SRC

Display endpoint coverage change:
  #+begin_src sql-mode :eval never-export :exports both :session none
    select * from projected_change_in_coverage;
  #+end_src

  #+RESULTS:
  #+begin_SRC example
     category    | total_endpoints | old_coverage | new_coverage | change_in_number 
  ---------------+-----------------+--------------+--------------+------------------
   test_coverage |             438 |          190 |          194 |                4
  (1 row)

  #+end_SRC

* Final notes :export:
If a test with these calls gets merged, **test coverage will go up by 4 points**

This test is also created with the goal of conformance promotion.

-----  
/sig testing
 
/sig architecture  

/area conformance  

* Open Tasks
  Set any open tasks here, using org-todo
** DONE Live Your Best Life
* Footnotes                                                     :neverexport:
  :PROPERTIES:
  :CUSTOM_ID: footnotes
  :END:
