#+NAME: APISnoop WebUI
#+AUTHOR: Zach Mandeville
#+EMAIL: zz@ii.coop
#+TODO: TODO(t) NEXT(n) IN-PROGRESS(i) BLOCKED(i) | DONE(d) DONE-AND-SHARED(!)
#+PROPERTY: header-args :dir (file-name-directory buffer-file-name)
#+XPROPERTY: header-args:shell :results silent
#+XPROPERTY: header-args:shell :exports code
#+XPROPERTY: header-args:shell :wrap "SRC text"
#+PROPERTY: header-args:tmate :socket "/tmp/.zz-left.isocket"
#+PROPERTY: header-args:tmate :session api:main

* NOTICE: File has split.  Visit client or backend to see their specific org files!
* Introduction
  This is a web-based visual interface to the data curation and manipulation we are doing as the APISnoop project.  The purpose is to display previously unseen connections between the testing coverage of kubernetes, and the people and communities these various parts of kubernetes matter to.
** Reimagining how the web app is built.
   At this point, the work here is a proof of concept refactoring of the orignal site, to make our structure more extensible and modular.  When new work is done with the dating processing, we want to be able to quickly visualize the results of this work for others.  The current site is static html, with each new section intentionally and manually hard-coded. Whenever we want to make a change to the site (like adding a new dataset), it requires going into the html file, finding the right section, and adding a new element.  We have to keep a mental map of every aspect of the site this new dataset should influence and update those accordingly.  Not only is this time-consuming, it's error-prone and hard to maintin.

   At the same time, there was a good amount of work done by the team to get to the current site, and that work should be preserved as much as possible.  The goal of this refactor, then, is to re-make the original site to then build incredible things beyond and above it.
http://uber.github.io/react-vis/documentation/other-charts/sunburst-diagram
** Setting It up On Your own
*** Setup Backend
 after cloning repository
- cd apisnoop/backend
- npm install
- Make sure we have a jsons folder in apisnoop/backend with this tree structure:
#+RESULTS: File Structure
:RESULTS:
.
├── release
└── sunbursts

2 directories
:END:
#+NAME: File Structure
#+BEGIN_SRC shell :dir ./backend/jsons :results output raw drawer
tree -d
#+END_SRC
- Delete all .db's from src/data/
- npm start
- email zz@ii.coop with full error output and a coupon for soda.

*** Setup Client
    When backend server is on:
    - cd apisnoop/client
    - npm install
    # - figure out how to point to subheadings
    - go to [[Client/Actions/index.js]]   and change the client here to be whatever site you have this on (localhost or apisnoop)
    - npm start

* Architecture
The site will be made to have a distinct front-end and backend, with the front-end able to be ported over to any other backend.
The front-end will consist of multiple components that wait to be told what data to display, instead of being written as part of the component.  In this way, if we want to make changes to our 'SIG Tag Bubble', we can just find the component named that and make changes there, instead of trying to find/replace the code within the file.
** Client
You can view the org file specific to the client at [[file:client/client.org][./client/client.org]]
The frontend will be made with React, Redux, maybe Saga, and Tachyons, and Axios
*** Why React?
    [[https://reactjs.org/][React]] is the most well-known and supported front-end framework among my dev friends in Wellington, and is widely used and respected globally.  It was created originally by Facebook and then made open-source.  So it has a tremendous amount of support around it and good video tutorials for learning it.  I find it to be a bulky and kinda clumsy framework (which is why the first version of this used my personal fave Choo instead), but felt it was good to pick one that more people knew (and could help with).

*** Why Redux?
   [[https://redux.js.org/][Redux]]  provides one global 'state' for the app, and makes React actually usable.  It will help us push the data appropriately to the right parts and keep things clean and efficient.

    - [ ] Query endpoints by Release.
*** Reselect
   [[https://github.com/reduxjs/reselect][Reselect]]  allows us to massage the state into friendly props specific to components.  This helps us keep a philosophy that nothing in the state is repeated, and instead you have //all// state that you can then derive into different selectors based on what you need for the component.
   #+NAME: install Reselect
   #+BEGIN_SRC shell :dir ./client :results output list raw
npm install reselect
   #+END_SRC

   #+RESULTS: install Reselect
   - + reselect@4.0.0
   - added 1 package, removed 15 packages and audited 21041 packages in 14.857s
   - found 1 low severity vulnerability
   - run `npm audit fix` to fix them, or `npm audit` for details

*** AXIOS
   [[https://www.npmjs.com/package/axios][Axios]] is a simple tool for handling http requests across different servers.  We'll need this for the client to be portable, and able to call to multiple API's (our backend plus github for example).
*** Why Tachyons?
    Tachyons is a css framework for writing functional CSS.  It's a much different approach to CSS, but it's one that matches a unix philosophy and is super easy to spin things up and maintain them.  AS we make changes, we don't have to worry that some class hidden deep in some css file causes our whole site to look weird.  Instead, every class has a single purpose, and you add multiple classes to a site to add-upon and combine each of these classes functions (like piping commands together on the command line).  This makes all our components //reusable// too, as we only need to copy over the code and not any stylesheet attached to the code.

** BACKEND
   You can view the org specific to the backend at [[file:backend/backend.org][./backend/backend.org]]
   For the backend we will be using Feathers //for right now//.  We may find that we want something completely different, or that we want our webui to be able to live in multiple places.  Our goal is for the client to not care about where it's info is coming from, as long as the api paths are the same.

*** Feathers
    [[https://feathersjs.com/][Feathers]] is a well-designed and well-documented api layer written in Node.  It has good support among my Wellington dev friends, and so I have better help if I encounter any sorta problem.  It also is just really pleasant to use so far, with a good model for how to create different services.  It also has an existing React connector.
**** Feathers Resources
***** [[https://www.youtube.com/playlist?list=PLwSdIiqnDlf_lb5y1liQK2OW5daXYgKOe][youtube channel]]
***** [[https://stackoverflow.com/questions/tagged/feathersjs][stackoverflow tag]]
***** [[https://github.com/issues?utf8=%25E2%259C%2593&q=is%253Aopen+is%253Aissue+user%253Afeathersjs+][github page]]
***** [[https://blog.feathersjs.com/][medium page]]
***** [[http://slack.feathersjs.com/][slack channel]]

* Process
** Resources
*** d3
**** [[https://medium.com/@Elijah_Meeks/interactive-applications-with-react-d3-f76f7b3ebc71][interactive applications with react-d3]]
     this is really good.
**** [[https://www.smashingmagazine.com/2018/02/react-d3-ecosystem/][Bringing Together react, d3, and their ecosystem]]
**** [[http://www.adeveloperdiary.com/react-js/integrate-react-and-d3/][How to Integrate React and d3 the right way]]
**** [[https://bost.ocks.org/mike/join/][Thinking with Joins]]
*** react/redux
    - [[https://read.reduxbook.com][Human Redux, by Henrik Joreteg]]

** isocket
*** Connecting the left pair / isocket

 ssh needs '-t' twice because it needs to be forced to allocate a remote terminal
 _even_ when we don't have have local one (within emacs)


#+NAME: left_session_create
#+BEGIN_SRC shell :var session="zz-left" terminal_exec="xterm -e" user="zz" host="apisnoop.cncf.io" :session nil :results silent
  $terminal_exec \
      "ssh -att \
           -L /tmp/.$session.isocket:/tmp/.$session.isocket \
           -l $user \
           $host \
      tmate -S /tmp/.$session.isocket \
            new-session \
            -A \
            -s $session \
            -n emacs \
      emacs --fg-daemon=$session" \
  &
#+END_SRC

#+NAME: left_session_setup
#+BEGIN_SRC shell :var session="zz-left" user="zz" host="apisnoop.cncf.io" :session nil :results silent
  ssh -att $user@$host \
  "tmate -S /tmp/.$session.isocket \
        new-window \
        -n client" \
   "emacsclient -nw \
              --socket-name $session \
              ~/apisnoop/webui/web_ui.org"
#+END_SRC

 #+NAME: left_session
 #+BEGIN_SRC shell :wrap "SRC text :noeval" :results verbatim :var session="zz-left" user="zz" host="apisnoop.cncf.io" :results silen
  ssh -att $user@$host \
    tmate -S /tmp/.$SESSION.isocket wait tmate-ready > /dev/null &&
  ssh -att $user@$host \
    tmate -S /tmp/.$SESSION.isocket display -p \'#{tmate_ssh}\' 2> /dev/null
# ssh -tt root@apisnoop.cncf.io \
#  tmate -S /tmp/.$SESSION.isocket display -p \'#{tmate_ssh}\'
 #+END_SRC

 #+RESULTS: left_session
 #+BEGIN_SRC text :noeval
 #+END_SRC

**** Connecting to emacs daemon

 #+NAME: alse run emacsclient
 #+BEGIN_SRC tmate :noeval
 export SESSION=lt-emacs
 emacsclient --socket-name $SESSION
 #+END_SRC

*** Connecting the right pair / isocket

#+NAME: right_session_create
#+BEGIN_SRC shell :var session="zz-right" terminal_exec="xterm -e" user="zz" host="apisnoop.cncf.io" :session nil :results silent
  $terminal_exec \
      "ssh -att \
           -L /tmp/.$session.isocket:/tmp/.$session.isocket \
           -l $user \
           $host \
      tmate -S /tmp/.$session.isocket \
            new-session \
            -A \
            -s $session \
            -n misc" \
  &
#+END_SRC


 #+NAME: right_session_join
 #+BEGIN_SRC shell :results silent
 export SESSION=api-snoop
 export XTERM_EXEC="roxterm -e"
 $XTERM_EXEC ssh -Att root@apisnoop.cncf.io \
  tmate -S /tmp/.$SESSION.isocket \
   at \; sleep 9999
 #+END_SRC

 #+NAME: right_session_setup
 #+BEGIN_SRC shell :results verbatim
 export SESSION=api-snoop
 echo ssh -tt root@apisnoop.cncf.io \
  tmate -S /tmp/.$SESSION.isocket \
    new-window -n session \
     bash
 #+END_SRC

 #+NAME: right_session
 #+BEGIN_SRC shell :cache yes :wrap "SRC text :noeval" :results verbatim
 export SESSION=api-snoop
 ssh -tt root@apisnoop.cncf.io \
  tmate -S /tmp/.$SESSION.isocket display -p \'#{tmate_ssh}\'
 #+END_SRC

 #+RESULTS[dd96525b42bbbe741e292e99ad5f3592a7163025]: right_session
 #+BEGIN_SRC text :noeval
 ssh mJrsCgvGTOTOFagYpBKvRf7EE@sf2.tmate.io
 #+END_SRC





 #+NAME: give this to your pair
 #+BEGIN_SRC bash :noweb yes :var left_session=left_session() right_session=right_session()
 echo "ii pair session ready
 left: $left_session
 right: $right_session
 "
 #+END_SRC

 #+RESULTS: give this to your pair
 | ii     | pair | session | ready |
 | left:  | nil  |         |       |
 | right: | nil  |         |       |
 |        |      |         |       |

*** TODO Sharing your eyes

#+NAME: give this to your pair
#+BEGIN_SRC bash :noweb yes :var left_session=left_session() :var right_session=right_session()
echo "ii pair session ready
left: $left_session
right: $right_session
"
#+END_SRC
** Working with d3
*** Introduction
   d3 is the data visualization library that was used to make our original sunburst.  The way it works is to mount itself to the dom, and then appends new elements to the dom based on the data it was given. If that data changes, it transforms the elements as needed.

   The way react works is it attaches itself to the dom, then creates a //shadow dom// that it is continually listening to, adding and removing elements in this dom as needed based on the data(the state) it was given.

   In other words, they work in largely the same way, and both wanna attach themselves to the dom and manipulate it.  This...isn't good.  We want to have /1/ thing making shadow doms and calls on the website, and so it is a bit tricky to get react and d3 working together.

The upside is that a number of people have tackled this challenge and created different react/d3 libraries for how the two can work together.  The downside is that I'm not sure yet which is the best to do.

Put simply, it is not easy to take our existing sunburst code and just paste it into our new app.  We are going to need to transform it in some way based on the guidance of the library we are using.

So the question is why we are putting ourselves into this trouble?
*** WHY WE ARE PUTTING OURSELVES INTO THIS TROUBLE
    My assumption with all of this is that when people hear 'apisnoop', they are thinking of the site in which you can see the data visualziations.  And so the webapp is important for the project and will be expanded.  React would be great for this in the long run.

Similarly, I am expecting that we are going to have more types of visualizations than just the sunburst--and that even the sunburst may change.  So we are going to want to have an understanding for a language in which we can make a //bunch// of visualizations. d3 is great for this.

If we do it right, we can have reusable components too that other teams could use for their own k8s projects, and that we could use ourselves.  For example--displaying two sunburst charts side by side would be much easier in react/d3 then what i ws trying to do before (appending both to the same id on a standard html document.)  This requires that I move through some d3 tutorials though.

At the end of this, though, we will have a backend server that is easy to setup and can ping different url's (github repos or testgrid artifacts) and grab their data.  Then, we can manipulate that data in whatever way we want but also pass it along to our frontend.  This front-end can then have different options and tags setto really dive in and explore.

If this is the purpose of apisnoop then let's do it.  If it's too much overkill though, then I can try a simpler solution.
*** Possible Process to get going
**** Setup a simple d3 visualization to understand the process
**** pipe data into this simple visualization through our redux state.
**** Pore over the original code again (the original blog post) to see how to best convert it
**** Change the sunburst's origin point from a CSV file to JSON
**** Change the sunbursts origin point from JSON to our redux store.
*** Second Process
**** Setup different pages for different d3-react libraries that already have ubilt components.
**** explore piping our data into the one we like.
**** Use testgrid conformance data and make simple visualizations to it.
     We are wanting to keep the data retrieval tied into the visualizing, so we dont' end up with a pretty graph that can't be used for what we have.  So we can grab the testgrid stuff now and see what we can do with it.


**** Use that going forward.
*** Possible Libraries to use
**** Victory
     https://formidable.com/open-source/victory/
**** Britecharts react
     https://eventbrite.github.io/britecharts-react/
**** Recharts
     http://recharts.org/en-US/
** Aaron Feedback
- useful troubleshooting tool:
  - adding test names to user agents to verify a test was testing what we thought it was.
  - filter audit logs by user-agent and then see 'when this test case is run, here are the endpoints it accesses chronologically".
    - This is separate from number of times hit.  that is useful in aggregate, this is something different.
  - pulling in an audit log of timestamp/verb/uri
- Feature of pointing to the specific line in the source for each test, to pull its definition, would be a good //Next// step.
  - This is something we can do with whakapapa, but it's not something we have now.
- Discovery front: Filtering more endpoints from APIsnoop's definition of coverage.
  - If beta endpoints always get hit because an api server is doing discovery, then that's cool but nothing we can ever prevent conformance tests from doing and we shouldn't care about it from a test coverage perspective.
  - How do we signify that this is the kinda hit that's happening for an endpoint?
  - We have a good start with filtering to just e2e, but even our e2etests are hitting those endpoints.  There are some endpoints where, logically they don't need to get tested or anything like that.
  - Get to a point whwere we can manually specify, or have a blacklist of apiendpoints that we aren't factoring into our coverage viz.
  - One way to do this is to filter out the endpoints that are hit by nearly all of the tests.  This is a good indicator that the endpoint is for initialization or something like that, and not actually a part of this test's function.
- Unique Endpoints hit by a test: this is something that isn't covered by our sunburst or katherine's viz.  Pick a test, and then see the endpoints that are //only// hit by this test.
  - which endpoints hit are unique, versus which ones are common across all test cases.  This would let us know which test cases are doing good stuff and which endpoints are essentially meaningless.
  - you could have a center endpoint change to the perspective of that test, and then that test would only show the endpoints that it hits.....but that may not be that useful.  We dont' wanna see All the endpoints, we wanna see which ones are //special// for this test.
  - Hierarchy vizes aren't that useful.
  - I just wanna find a way to slice and dice data with raw queries and see where that leads us...and take some of the more useful queries and generate reports from that.  This sounds like a new approach for apisnoop.

Question from this, then: Who is apisnoop's audience?  Is it Aaron,and people like aaron?  is it a kubernetes end user?  If it's aaraon, he is saying he knows how to write certain queries, but he would rather have this  already done and then he can do further exploration.
'For an endpoint that's only hit three times, what are the tests that are hitting this endpoint.  And then we could follow up with what the tests are doing from an api perspective.  'Okay, now let me see the full api stream from this test."
 - auotmate this, or provide shiny reports for this.  This isn't the end user coming up with the interesting things, this is us coming up with interesting things that we are letting the end user come to their own conclusions on.
 - We eventually want to show api coverage going up over time across different builds. o
 - We might be able to format things in such a way to have a test dashboard that shows individual api endpoints and #'s: how many times they been hit, something like that.
 - Is code coverage a different thing?  when talking about it being a command line tool that generates reports from it...or is that just what the group is trying to do.  the benefit of the command line tool is that you can automate it running for every build. We could then just have a page that displays these reports even maybe.
 - We want to share shinies at kubeconf china.
 - Get visualization up to good place that replaces existing visualization.
 - Showing all the api accesses per user-agent or test as a different Dashboard to have.
 - Take care of you for whatever demos you need for apisnoop.
 - It would be worth it to show we're providing value to cncf as a whole, but right now it's good to just be able to have Aaron say that the work we're doing makes it easier for conformance to do the things they want to do.
 - Let's not work on things that don't end up providing value, over-delivering when he really just wants somethings maller and specific.  He's happy to have some reports that don't need to be that shiny, but maybe a little bit interactive.  and these reports would be:
   - If I click on a user agent, I can see the in-order access of all the api endpoints.
   - To get some kind of report that shows me what kind of endpoints don't matter (every test hits them) and which ones are interesting (cos only a few endpoints hit them) and what are those tests?
     - this may lead to a point where we try to make a whitelist of endpoints in our coverage, but let's not cross that bridge yet.
   - For wednesday deadline...this isn't a hard deadline, we can touch base on Tuesday/Monday and see where we at.
** Pairing With Mikey
*** Background
    I went through a pairing Session with [[https://dinosaur.is][Mikey]], to help with the overall architecture and code logic of the webui
* Experiment
  :PROPERTIES:
  :header-args: :dir (concat (file-name-directory buffer-file-name) "client")
  :header-args:tmate: :socket "/tmp/.zz-right.isocket"
  :header-args:tmate: :session "zz-right"
  :END:

# Local Variables:
# org-confirm-babel-evaluate: nil
# End:
